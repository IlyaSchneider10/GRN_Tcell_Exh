---
title: "Output_full_genome_new_workflow"
author: "Ilya"
date: "10/06/2022"
output: html_document
---
  
#Download packages
```{r}
#install.packages("BoolNet")

#install.packages("ggpubr")

#install.packages("Seurat")

#install.packages("RColorBrewer")

#install.packages("LaplacesDemon")

#install.packages(mousetrap)

#install.packages("https://cran.r-project.org/src/contrib/Archive/randomForest/randomForest_4.6-14.tar.gz", repos=NULL, type="source")

#install.packages("RColorBrewer")

#install.packages("igraph")

#install.packages("dplyr")

#install.packages("openxlsx")

#install.packages("gplots")

#if (!require("BiocManager", quietly = TRUE))
#   install.packages("BiocManager")
#BiocManager::install("GenomicRanges")

#if (!require("BiocManager", quietly = TRUE))
#   install.packages("BiocManager")
#BiocManager::install("TxDb.Hsapiens.UCSC.hg38.knownGene")

#if (!require("BiocManager", quietly = TRUE))
#   install.packages("BiocManager")
#BiocManager::install("Homo.sapiens")
 
#if (!require("BiocManager", quietly = TRUE))
#   install.packages("BiocManager")
#BiocManager::install("plyranges")

#install.packages("ellipsis")
#if (!require("BiocManager", quietly = TRUE))
#   install.packages("BiocManager")
#BiocManager::install("AUCell")

#if (!require("BiocManager", quietly = TRUE))
#install.packages("BiocManager")
#BiocManager::install("GSEABase")

#if (!require("BiocManager", quietly = TRUE))
#   install.packages("BiocManager")
#BiocManager::install("GEOquery")

#if (!require("BiocManager", quietly = TRUE))
    #install.packages("BiocManager")

#BiocManager::install("ComplexHeatmap")

#if (!require("BiocManager", quietly = TRUE))
    #install.packages("BiocManager")

#BiocManager::install("dorothea")
```

#Load packages
```{r}
update.packages("ellipsis")
#library(dplyr)
update.packages("htmltools")
library(GenomicRanges)
library(GenomicFeatures)
library(TxDb.Hsapiens.UCSC.hg38.knownGene)
library(Homo.sapiens)
library(plyranges)
library(AUCell)
library(GSEABase)
library(GEOquery)
library(openxlsx)
library(stringr)
library(gplots)
library(igraph)
library(RColorBrewer)
library(ComplexHeatmap)
library(randomForest)
library(mousetrap)
library(LaplacesDemon)
library(devtools)
library(RColorBrewer)
library(dorothea)
library(Seurat)
library(ggpubr)
library(BoolNet)
``` 

#Direcrories
```{r}
main_directory<-"/media/ag-cherrmann/ischneider/GRNTcellExh/scr"
data_directory<-"/media/ag-cherrmann/ischneider/GRNTcellExh/data"
analysis_directory<-"/media/ag-cherrmann/ischneider/GRNTcellExh/analysis"
```

#Edit the input file for the 50 Scenic runs
```{r eval=FALSE, echo=FALSE}
#Read input table
raw_input<-read.csv("/media/ag-cherrmann/cramirez/tcd8ExscSeq/data/maike2020/nina_thimme_raw_counts.csv",header=T, row.names=1)

#Read cell annotations
setwd(data_directory)
cell_annotations<-read.xlsx("nina_annotations.xlsx")

#Remove RNA genes
raw_input<-t(as.data.frame(raw_input))
raw_input<-raw_input[,17:dim(raw_input)[2]]

#Remove chromosme tags and duplicates
genes<-gsub("\\_.*","",colnames(raw_input))
remove<-which(duplicated(genes))
genes<-genes[-remove] 
raw_input<-raw_input[,-remove]
colnames(raw_input)<-genes
raw_input<-as.data.frame(raw_input)

#Bolouri paper nodes with appropriate nomenclature substitutions
paper_nodes<-c("HNF1A","TNFSF9","TNFRSF9","IL12RB1","IL12RB2","IL21R","FCER1G","CD3","CD8","CD28","PIK3K","EZH2","PRC2","IL2R","RAS","MAPK1","JUN","FOS","BATF","AKT1", "AKT2", "AKT3","FOXO1","EGR2","EGR3","BACH2","ID3","ID2","NFKB1","MTOR","IRF4","TCF3","NFATC2","PPARGC1A","BCL6","PRDM1","NFATC1","CXCR5","TBX21","ZEB2","LAG3","PDCD1","HIF1A","KLRG1","PPARA","CTLA4","HAVCR2","BTLA","NR4A1","CD160","TIGIT","IL15RA","CD244","CD2B4","MYC","RUNX3","EOMES","FAS","FASLG","GZMA","GZMB","PRF1","IFNG")
paper_substitutions<-list("HNF1A","TNFRSF9",c("IL12RB1","IL12RB2"),c("AKT1","AKT2","AKT3"),"TCF3","PRDM1","TBX21","PDCD1","PPARA","TNFSF9","FCER1G","MAPK1","PPARGC1A","IL15RA")
names(paper_substitutions)<-c("TCF1","41BB","IL12R","AKT","E2A","BLIMP1","TBET","PD1","PPAR","CD137L","CD3","MAPK","PGC1A","IL15R")

#Keep only cells with annotations
raw_input<-raw_input[cell_annotations$CELLID,]

#Keep only the genes that meet the filtering criteria
input<-raw_input[,names(which(colSums(raw_input)>2*0.01*nrow(raw_input))==T)]

#Include all paper nodes into the input table
paper_nodes_in_input<-paper_nodes[paper_nodes %in% colnames(input)]
paper_nodes_left_out<-paper_nodes[! paper_nodes %in% colnames(input)]
input<-cbind(input,raw_input[,which(colnames(raw_input) %in% paper_nodes_left_out)])
```

#Export the input table
```{r eval=FALSE, echo=FALSE}
setwd("/media/ag-cherrmann/ischneider/GRNTcellExh/data/SCENIC50/Input")
write.table(input, file='scenic_input_full_genome.tsv', quote=FALSE, sep='\t', row.names = T)
#Code for bash to iterate Scenic 50 times
#bash /media/ag-cherrmann/ischneider/GRNTcellExh/scr/Scenic.txt

#Save the table
setwd(analysis_directory)
write.table(input, file='scenic_input_full_genome.tsv', quote=FALSE, sep='\t', row.names = T)
```

#Open input table
```{r}
input<-read.table(paste0("/media/ag-cherrmann/ischneider/GRNTcellExh/data/SCENIC50/Input","/scenic_input_full_genome.tsv"),sep='\t',header=T)

#Bolouri paper nodes with appropriate nomenclature substitutions
paper_nodes<-c("HNF1A","TNFSF9","TNFRSF9","IL12RB1","IL12RB2","IL21R","FCER1G","FCER1G","CD8","CD28","PIK3K","EZH2","PRC2","IL2R","RAS","MAPK1","JUN","FOS","BATF","AKT1", "AKT2", "AKT3","FOXO1","EGR2","EGR3","BACH2","ID3","ID2","NFKB1","MTOR","IRF4","TCF3","NFATC2","PPARGC1A","BCL6","PRDM1","NFATC1","CXCR5","TBX21","ZEB2","LAG3","PDCD1","HIF1A","KLRG1","PPARA","CTLA4","HAVCR2","BTLA","NR4A1","CD160","TIGIT","IL15RA","CD244","CD2B4","MYC","RUNX3","EOMES","FAS","FASLG","GZMA","GZMB","PRF1","IFNG")
paper_substitutions<-list("HNF1A","TNFRSF9",c("IL12RB1","IL12RB2"),c("AKT1","AKT2","AKT3"),"TCF3","PRDM1","TBX21","PDCD1","PPARA","TNFSF9","FCER1G","MAPK1","PPARGC1A","IL15RA")
names(paper_substitutions)<-c("TCF1","41BB","IL12R","AKT","E2A","BLIMP1","TBET","PD1","PPAR","CD137L","CD3","MAPK","PGC1A","IL15R")

#Read cell annotations
setwd(data_directory)
cell_annotations<-read.xlsx("nina_annotations.xlsx")
cell_types<-split(cell_annotations,cell_annotations$TYPE)
cell_types<-cell_types[c(2,3,1)]

cell_types_cell_ids<-cell_types
for(x in names(cell_types)){
  cell_types_cell_ids[[x]]<-cell_types[[x]]$CELLID
}
```

#Select all TFs from aucell files
```{r}
#Number of scenic runs
n=50

#Open all aucell files and keep TFs from them
aucell_tfs<-vector("list",length=n)
names(aucell_tfs)<-seq(n)
for (x in seq(n)){
  aucell<-read.csv(paste0(data_directory,"/SCENIC50/Output_full_genome_new_workflow/run_",as.character(x),"/aucell.csv"),header=T,row.names = 1)
  aucell_tfs[[as.character(x)]]<-colnames(aucell)
}

aucell_tfs<-lapply(aucell_tfs, gsub, pattern="[...]",replacement="")
scenic_output_tfs<-unique(unlist(aucell_tfs))
```

#Get targets for TFs from reg files
```{r}
#Get target column from each reg file
reg_targets<-vector("list",length=n)
names(reg_targets)<-seq(n)
for (x in seq(n)){
  reg<-read.csv(paste0(data_directory,"/SCENIC50/Output_full_genome_new_workflow/run_",as.character(x),"/reg.csv"),header=T)
  reg_targets[[as.character(x)]]<-reg
}

change_reg_format<-function(r){
  names<-c(r[2,1:2],r[1,3:dim(r)[2]])
  y<-setNames(r,names)
  y<-y[-c(1,2),]
}

reg_targets<-lapply(reg_targets,change_reg_format)
for (x in names(reg_targets)){
  reg_targets[[x]]<-split(reg_targets[[x]],reg_targets[[x]]$TF)
}

for (x in names(reg_targets)){
  for (y in names(reg_targets[[x]])){
    reg_targets[[x]][[y]]<-reg_targets[[x]][[y]]$TargetGenes
  }
}

#Extract target names
extract_targets <- function(x){
  targets <- regmatches(x, gregexpr("'[^']*'", x))[[1]] 
  gsub("'", '', targets)
}

extract_all_unique_targets<-function(obj){
  unique(extract_targets(paste0(c(obj),collapse = "")))
}

for (x in names(reg_targets)){
  for(y in names(reg_targets[[x]])){
    reg_targets[[x]][[y]]<-extract_all_unique_targets(reg_targets[[x]][[y]])
  }
}

regulons<-reg_targets
for (x in names(reg_targets)){
  for(y in names(reg_targets[[x]])){
    reg_targets[[x]][[y]]<-reg_targets[[x]][[y]][reg_targets[[x]][[y]] %in% scenic_output_tfs] #we keep not only TF->TF interactions
  }
}

#Remove self regulation
for (y in names(reg_targets)){
  for (x in scenic_output_tfs){
    lookup<-x==reg_targets[[y]][[x]]
    pos<-which(lookup==T)
    if(sum(lookup)!=0){
      reg_targets[[y]][[x]]<-reg_targets[[y]][[x]][-c(pos)]
    }
  }
} 

#Remove TFs with no targets
for (x in names(reg_targets)){
  remove<-which(lapply(reg_targets[[x]], length)==0)
  reg_targets[[x]]<-reg_targets[[x]][-remove]
}

reg_tfs<-c()
for (x in names(reg_targets)){
  reg_tfs<-append(reg_tfs,names(reg_targets[[x]]))
}
reg_tfs<-unique(reg_tfs)
```

#Create a file with all the interactions that we want to keep
```{r}
#Put all interactions in dataframe form
all_interactions<-c()
for (z in names(reg_targets)){
  for(x in names(reg_targets[[z]])){
    for(y in reg_targets[[z]][[x]]){
      all_interactions<-append(all_interactions,paste0(x,"->",y))
    }
  }
}

frequency<-(table(all_interactions))
all_unique_interactions<-names(frequency)
interactions_summary<-as.data.frame(matrix(ncol=3,nrow=length(unlist(all_unique_interactions))))
colnames(interactions_summary)<-c("TF", "target","frequency")
interactions_summary$frequency<-as.numeric(frequency)
interactions_summary$TF<-sub("->.*", "", all_unique_interactions)
interactions_summary$target<-sub(".*->", "", all_unique_interactions)

#Add frequency filter
frequency_filter=40
for(x in seq(dim(interactions_summary)[1])){
  f<-interactions_summary$frequency[x]
  if(f>=frequency_filter){
    interactions_summary[x,"frequency_filter"]<-T
  }else{
    interactions_summary[x,"frequency_filter"]<-F
  }
}

#Dataframe for interactions that pass frequency filter
frequency_summary<-interactions_summary[which(interactions_summary$frequency_filter==T),]
frequency_summary_nodes<-unique(c(unique(frequency_summary$target),unique(frequency_summary$TF)))
```

#Caculate NIS score for frequency_summary interactions
```{r echo=FALSE, eval=FALSE}
#Open adj files
adj_files<-vector("list",length=n)
names(adj_files)<-seq(n)
for (x in seq(n)){
  adj<-read.table(paste0(data_directory,"/SCENIC50/Output_full_genome_new_workflow/run_",as.character(x),"/adj.tsv"),sep='\t',header=T)
  adj_files[[as.character(x)]]<-adj
}

#Filter for interactions that are present in frequency_summary
adj_frequency_files<-adj_files
for(y in names(adj_files)){
  keep<-c()
  for (x in seq(nrow(frequency_summary))){
    tf_rows<-which(adj_files[[y]]$TF==frequency_summary[x,]$TF)
    target_rows<-which(adj_files[[y]]$target==frequency_summary[x,]$target)
      if(length(tf_rows)!=0 & length(target_rows)!=0){
       pos<-which(tf_rows %in% target_rows)
        if(length(pos)!=0){
           keep<-append(keep,tf_rows[pos])
        }
      }
  }
  adj_frequency_files[[y]]<-adj_files[[y]][keep,]
}

#Average the importance scores
adj_frequency_files_importance_scores<-vector("list", nrow(frequency_summary))
names(adj_frequency_files_importance_scores)<-seq(nrow(frequency_summary))
for (x in seq(nrow(frequency_summary))){
  imp<-c()
  for(y in names(adj_frequency_files)){
    tf_rows<-which(adj_frequency_files[[y]]$TF==frequency_summary[x,]$TF)
    target_rows<-which(adj_frequency_files[[y]]$target==frequency_summary[x,]$target)
      if(length(tf_rows)!=0 & length(target_rows)!=0){
      pos<-which(tf_rows %in% target_rows)
        if(length(pos)!=0){
          imp<-append(imp,adj_frequency_files[[y]][tf_rows[pos],]$importance)
        }
      }
  }
  adj_frequency_files_importance_scores[[x]]<-mean(imp)
}

#Add IS to the frequency_summary
frequency_summary["IS"]<-unlist(adj_frequency_files_importance_scores)*frequency_summary$frequency

#Split frequency_summary by targets
frequency_summary_targets<-split(frequency_summary,frequency_summary$target)

#Calculate NIS
all_nis<-c()
for (x in names(frequency_summary_targets)){
  nis<-c()
  for (y in seq(nrow(frequency_summary_targets[[x]]))){
    score<-frequency_summary_targets[[x]]$IS[y]/sum(frequency_summary_targets[[x]]$IS)
    nis<-append(nis,score)
  }
  all_nis<-append(all_nis,nis)
}

frequency_summary["NIS"]<-all_nis

#Save the table
write.csv(frequency_summary,paste0(analysis_directory,"/frequency_summary.csv"), row.names = F)
```

#Import frequency_summary
```{r}
frequency_summary<-read.csv(paste0(analysis_directory,"/frequency_summary.csv"),header=T)
```

#Select best peaks for cistrome
```{r eval=FALSE, echo=FALSE}
#Work with cistrome description file
setwd(data_directory)
cistrome_description<-read.delim("human_factor_full_QC.txt")
cistrome_blood<-cistrome_description[cistrome_description$Tissue_type=="Blood",]

#File 38912 is empty and gives us an error in the loop so we remove it
cistrome_blood<-cistrome_blood[cistrome_blood$DCid!=38912,]
cistrome_blood_file_names<-cistrome_blood$DCid

#Open corresponding files
cistrome_blood_files<-vector("list", length(cistrome_blood_file_names))
names(cistrome_blood_files)<-cistrome_blood_file_names
for (x in cistrome_blood_file_names){
  cistrome_blood_files[[as.character(x)]]<-as.data.frame(read.table(paste0(data_directory,"/human_factor/",as.character(x),"_sort_peaks.narrowPeak.bed"),header = FALSE, sep="\t",stringsAsFactors=FALSE, quote=""))
}

#Keep only TFs that appear in scenic output
names(cistrome_blood_files)<-cistrome_blood$Factor
cistrome_blood_files<-cistrome_blood_files[names(cistrome_blood_files) %in% scenic_output_tfs]

#Split the list into groups according to a TF
cistrome_blood_files<-split(cistrome_blood_files,names(cistrome_blood_files))
cistrome_blood_files<-lapply(cistrome_blood_files, dplyr::bind_rows)

#Select top 6000 peaks for each TF
cistrome_best_peaks<-cistrome_blood_files
for (y in names(cistrome_best_peaks)){
  best_peaks<-unique(head(sort(cistrome_best_peaks[[y]]$V5, decreasing=T),6000))
  keep<-c()
  for (x in best_peaks){
    keep<-append(keep,which(cistrome_best_peaks[[y]]$V5==x))
  }
  cistrome_best_peaks[[y]]<-cistrome_best_peaks[[y]][keep,]
}

#Export cistrome_best_peaks
for (x in names(cistrome_best_peaks)){
  write.csv(cistrome_best_peaks[[x]],paste0(analysis_directory,"/","cistrome_best_peaks/",x,".csv"), row.names = F)
}
```

#Import cistrome_best_peaks
```{r}
best_peaks_file_names<-list.files(paste0(analysis_directory,"/","cistrome_best_peaks"))
cistrome_best_peaks<-list()
for (x in seq_along(best_peaks_file_names)){
  cistrome_best_peaks[[x]]<-read.csv(paste0(analysis_directory,"/","cistrome_best_peaks/",best_peaks_file_names[x]))
}
names(cistrome_best_peaks)<-sub(".csv*.", "", best_peaks_file_names)
```

#Prepare Cistrome peaks for intersection with reference genome
```{r}
#Change peak format
change_peak_format<-function(peak){
  y<-peak[,c(1,2,3,6)]
  new_names<-c("chr","start","end","strand")
  setNames(y,new_names)
}
cistrome_best_peaks<-lapply(cistrome_best_peaks,change_peak_format)

#Extend the peaks by 1 kb in both directions
extension=1000
extend_peaks<-function(peak, e){
  peak<-mutate(peak,start=start-e)
  peak<-mutate(peak,end=end+e)
}
cistrome_extended_peaks<-lapply(cistrome_best_peaks,extend_peaks,e=extension)
for(y in names(cistrome_extended_peaks)){
  for (x in seq_along(cistrome_extended_peaks[[y]]$start)){
    if(cistrome_extended_peaks[[y]]$start[x]<0){
      cistrome_extended_peaks[[y]][x,2]<-0
    }
  }
}
cistrome_granges_peaks<-cistrome_extended_peaks

#Make Granges objects
for (x in names(cistrome_extended_peaks)){
  cistrome_granges_peaks[[x]]<-makeGRangesFromDataFrame(cistrome_extended_peaks[[x]])
}
```

#Overlap peaks with reference genome
```{r}
#Get reference transcripts
txdb <- TxDb.Hsapiens.UCSC.hg38.knownGene
transcripts <- GenomicFeatures::genes(txdb)

#Get reference genes
TxDb(Homo.sapiens) <- txdb
genes_list <- transcriptsBy(Homo.sapiens, columns = "SYMBOL")
genes <- unlist(genes_list)
cistrome_overlap_transcripts<-lapply(cistrome_granges_peaks, GenomicRanges::intersect, y=transcripts, ignore.strand=T)

#Create overlap and obtain gene names
cistrome_overlap_genes<-lapply(cistrome_overlap_transcripts,plyranges::find_overlaps,y=genes)
cistrome_overlap_gene_names<-lapply(cistrome_overlap_genes,function(x){unique(unlist(x$SYMBOL))})
total_genes<-unique(unlist(cistrome_overlap_gene_names))
scenic_cistrome_overlap<-scenic_output_tfs[scenic_output_tfs %in% total_genes]
cistrome_overlap_gene_names<-lapply(cistrome_overlap_gene_names, function(x){x[x %in% scenic_output_tfs]})

#Add cistrome filter to interactions_summary
cistrome_confirmed_interactions<-c()
for (z in names(cistrome_overlap_gene_names)){
  for(y in cistrome_overlap_gene_names[[z]]){
    cistrome_confirmed_interactions<-append(cistrome_confirmed_interactions,paste0(z,"->",y))
  }
}
our_cistrome_confirmed_interactions<-cistrome_confirmed_interactions[cistrome_confirmed_interactions %in% all_unique_interactions]
interactions_summary["cistrome_filter"]<-F
interactions_summary[which(all_unique_interactions %in% our_cistrome_confirmed_interactions),"cistrome_filter"]<-T

#Dataframe for interactions that pass cistrome filter
cistrome_summary<-interactions_summary[which(interactions_summary$cistrome_filter==T),]
cistrome_summary_nodes<-unique(c(unique(cistrome_summary$TF),unique(cistrome_summary$target)))

#Dataframe for interactions that pass frequency and cistrome filter
frequency_cistrome_summary<-interactions_summary[which(interactions_summary$cistrome_filter==T &interactions_summary$frequency_filter==T),]
frequency_cistrome_summary_nodes<-unique(c(unique(frequency_cistrome_summary$target),unique(frequency_cistrome_summary$TF)))
```

#Dorothea
```{r}
#Look up which interactions are confirmed by dorothea
confirmed<-c()
for (x in seq(nrow(frequency_summary))){
  tf<-which(frequency_summary$TF[x]==dorothea_hs$tf)
  target<-which(frequency_summary$target[x]==dorothea_hs$target)
  pos<-tf %in% target
  if(length(pos)!=0){
    confirmed<-append(confirmed,tf[pos])
  }
}

#Kepp only A confidence
dorothea_keep<-dorothea_hs[confirmed,]
dorothea_keep<-dorothea_keep[which(dorothea_keep$confidence=="A"),]

#Mark those in frequency table
keep<-c()
for (x in seq(nrow(dorothea_keep))){
  tf<-which(dorothea_keep$tf[x]==interactions_summary$TF)
  target<-which(dorothea_keep$target[x]==interactions_summary$target)
  pos<-tf %in% target
  if(length(pos)!=0){
    keep<-append(keep,tf[pos])
  }
}

interactions_summary["dorothea_filter"]<-F
interactions_summary[keep,"dorothea_filter"]<-T
frequency_dorothea_summary<-interactions_summary[which(interactions_summary$dorothea_filter==T & interactions_summary$frequency_filter==T),]
```

#ATAC-seq data
```{r}
#Selecet only targets and TFs from atac_seq file
atac_seq<-read.table(paste0(data_directory,"/CHaRs_annotated.tsv"),sep='\t',header=T)
keep<-c()
for (x in seq(dim(atac_seq)[1])){
  if(atac_seq$genes[x]!=""){
    keep<-append(keep,x)
  }
}
atac_seq<-atac_seq[keep,]
atac_seq_list<-vector("list", dim(atac_seq)[1])
names(atac_seq_list)<-atac_seq$genes
for (x in seq(length(atac_seq_list))){
  
  str<-atac_seq$TF[[x]]
  
  one<-sub(";.*", "", str)
  two<-str_match_all(str, ";\\s*(.*?)\\s*;")[[1]][,2]
  three<-sub(".*;", "", str)
  
  res<-c(one, two, three)
  
  atac_seq_list[[x]]<-res
  
}
atac_seq_list<-split(atac_seq_list,names(atac_seq_list))
atac_seq_list<-lapply(atac_seq_list,unlist)
atac_seq_list<-lapply(atac_seq_list, unique)
#Deal with complex target names
multiple_targets<-atac_seq_list[grep(";", names(atac_seq_list))]
converted_targets<-list()
for (x in names(multiple_targets)){
  one<-sub(";.*", "", x)
  two<-str_match_all(x, ";\\s*(.*?)\\s*;")[[1]][,2]
  three<-sub(".*;", "", x)
  
  res<-c(one, two, three)
  
  for (y in res){
    converted_targets[[y]]<-multiple_targets[[x]]
  }
}
atac_seq_list<-atac_seq_list[-which(names(atac_seq_list) %in% names(multiple_targets))]
atac_seq_list<-c(converted_targets,atac_seq_list)
atac_seq_list<-split(atac_seq_list,names(atac_seq_list))
atac_seq_list<-lapply(atac_seq_list,unlist)
atac_seq_list<-lapply(atac_seq_list, unique)
#Keep only TF->TF interactions
atac_seq_list<-atac_seq_list[which(names(atac_seq_list) %in% scenic_output_tfs)]
for (x in names(atac_seq_list)){
  atac_seq_list[[x]]<-atac_seq_list[[x]][atac_seq_list[[x]] %in% scenic_output_tfs]
}
#Create ATAC-seq interactions
atac_seq_interactions<-c()
for (x in names(atac_seq_list)){
  for(y in atac_seq_list[[x]]){
    atac_seq_interactions<-append(atac_seq_interactions,paste0(y,"->",x))
  }
}
#Add interactions to the interactions_summary table 
interactions_summary["ataq-seq"]<-F
interactions_summary[which(all_unique_interactions %in% atac_seq_interactions),"ataq-seq"]<-T
interactions_summary[interactions_summary$`ataq-seq`==T,]
#Dataframe for interactions that pass ataq_seq filter
ataq_seq_summary<-interactions_summary[which(interactions_summary$`ataq-seq`==T),]
#Dataframe for interactions that pass frequency and ataq_seq filter
frequency_ataq_seq_summary<-interactions_summary[which(interactions_summary$`ataq-seq`==T & interactions_summary$frequency_filter==T),]
frequency_ataq_seq_summary_nodes<-unique(c(unique(frequency_ataq_seq_summary$TF),unique(frequency_ataq_seq_summary$target)))
```

#Unite all confirmed interactions in one file
```{r}
find_same_interactions_dfs<-function(df_to_compare,reference_df){
  confirmed<-c()
  for (x in seq(nrow(reference_df))){
    tf<-which(reference_df$TF[x]==df_to_compare$TF)
    target<-which(reference_df$target[x]==df_to_compare$target)
    pos<-tf %in% target
      if(length(pos)!=0){
       confirmed<-append(confirmed,tf[pos])
      }
  }
  return(confirmed)
}

frequency_confirmed_interactions_summary<-frequency_summary
frequency_confirmed_interactions_summary["confirmed_interactions"]<-F

cistrome_confirmed<-find_same_interactions_dfs(frequency_summary,frequency_cistrome_summary)
dorothea_confirmed<-find_same_interactions_dfs(frequency_summary,frequency_dorothea_summary)
ataq_seq_confirmed<-find_same_interactions_dfs(frequency_summary,frequency_ataq_seq_summary)

confirmed<-unique(c(cistrome_confirmed,dorothea_confirmed,ataq_seq_confirmed))

frequency_confirmed_interactions_summary[confirmed,"confirmed_interactions"]<-T
frequency_confirmed_interactions_summary<-frequency_confirmed_interactions_summary[which(frequency_confirmed_interactions_summary$confirmed_interactions==T),]
```

#Select regulons for binarizing their aucell scores
```{r eval=FALSE, echo=FALSE}
#Filter regulons list for TFs that pass frequency filter
frequency_regulons<-vector("list", length(regulons))
names(frequency_regulons)<-names(regulons)
for (x in names(regulons)){
  keep<-names(regulons[[x]])[names(regulons[[x]])%in% frequency_summary_nodes]
  frequency_regulons[[x]]<-regulons[[x]][keep]
}

#Remove the scenic runs list levels and unite all the targets of each TF as one entry
regulon_targets<-vector("list", length(frequency_summary_nodes))
names(regulon_targets)<-frequency_summary_nodes
for (y in frequency_summary_nodes){
  a<-list()
  for (x in names(frequency_regulons)){
    if (sum(y==names(frequency_regulons[[x]]))!=0){
    pos<-which(names(frequency_regulons[[x]])==y)
    a[[x]]<-frequency_regulons[[x]][[pos]]
    }
  }
  regulon_targets[[y]]<-a
}
```

#Conduct new aucell for the selected regulons
```{r eval=FALSE, echo=FALSE}
#Keep only unique interactions that satisfy our frequency criteria
for (x in names(regulon_targets)){
  regulon_targets[[x]]<-sort(table(unlist(regulon_targets[[x]])),decreasing = T)
}

for (x in names(regulon_targets)){
  regulon_targets[[x]]<-names(which((regulon_targets[[x]]>=1)==T))
}

#Remove small regulons: < 15 interactions
remove<-which(lapply(regulon_targets, length)<15)
remove_names<-names(remove)
regulon_targets<-regulon_targets[-remove]

#Select only the cells that have a cell type assigned to it
input_for_single_aucell<-t(input)
input_for_single_aucell<-input_for_single_aucell[,cell_annotations$CELLID]

#Run AUCell
expr_matrix <- as(input_for_single_aucell, "dgCMatrix")
cells_rankings<-AUCell_buildRankings(expr_matrix)

cells_AUC <- AUCell_calcAUC(regulon_targets, cells_rankings)
cells_assignment <- AUCell_exploreThresholds(cells_AUC, plotHist=F, assign=TRUE)
```

#Make a heatmap to represent the aucell scores
```{r eval=FALSE, echo=FALSE}
#Get AUCell matrix
aucell_scores<-as.data.frame(getAUC(cells_AUC))

#Get cell ids grouped accroding to phenotype in the AUCell matrix
cell_ids_ordered<-c()
for (x in names(cell_types)){
  cell_ids_ordered<-append(cell_ids_ordered,cell_types[[x]]$CELLID)
}

aucell_scores<-aucell_scores[,cell_ids_ordered]
aucell_scores<-aucell_scores[sort(rownames(aucell_scores)),]

#Make a heatmap
pdf(paste0(analysis_directory,'/figures/new_aucell_not_norm.pdf'),
     width=15,
     height=40)

Heatmap(aucell_scores,cluster_rows = F,cluster_columns = F, column_labels = rep("",length(colnames(aucell_scores))), column_split = rep(names(cell_types), times = c(dim(cell_types[[1]])[1],dim(cell_types[[2]])[1],dim(cell_types[[3]])[1])))
dev.off()

aucell_scores_norm<-t(scale(t(aucell_scores)))

pdf(paste0(analysis_directory,'/figures/new_aucell_norm.pdf'),
     width=15,
     height=40)

Heatmap(aucell_scores_norm,cluster_rows = F,cluster_columns = F, column_labels = rep("",length(colnames(aucell_scores))), column_split = rep(names(cell_types), times = c(dim(cell_types[[1]])[1],dim(cell_types[[2]])[1],dim(cell_types[[3]])[1])))
dev.off()

#Test distributions of aucell scores for bimodality
sum(apply(aucell_scores, 1, is.bimodal))/dim(aucell_scores)[1]
sum(apply(aucell_scores, 1, bimodality_coefficient)>0.555)/dim(aucell_scores)[1]

#Distributions of aucell scores within each cell_type
aucell_scores_norm_cell_types<-cell_types_cell_ids
for (x in names(cell_types_cell_ids)){
  aucell_scores_norm_cell_types[[x]]<-aucell_scores_norm[,cell_types_cell_ids[[x]]]
}

aucell_scores_norm_cell_types<-lapply(aucell_scores_norm_cell_types, rowMeans)

for (x in aucell_scores_norm_cell_types){
  hist(x, breaks=50)
}
```

#Random Forest to identify TFs that explain the most cell phenotypes
```{r eval=FALSE, echo=FALSE}
#Create dataframe for the random forest
random_forest_input<-rbind(rep(names(cell_types), times = c(dim(cell_types[[1]])[1],dim(cell_types[[2]])[1],dim(cell_types[[3]])[1])),aucell_scores)
rownames(random_forest_input)[1]<-"cell_type"
random_forest_input<-as.data.frame(t(random_forest_input))

#Create a Random Forest model with default parameters
aucell_model <- randomForest(as.factor(cell_type) ~ ., data = random_forest_input, importance = TRUE)
aucell_model_importance<-as.data.frame(importance(aucell_model))
aucell_model_importance<-aucell_model_importance[order(aucell_model_importance$MeanDecreaseAccuracy, decreasing = T),]

#See which Tfs we keep for further interactions
varImpPlot(aucell_model) #Top 30 ones are represented at htis graph so we keep them
aucell_model_importance_top30<-head(rownames(aucell_model_importance),30)
aucell_model_importance_top100<-head(rownames(aucell_model_importance),100)

#Save the tables
write.csv(aucell_model_importance_top100 ,paste0(analysis_directory,"/aucell_model_importance_top100.csv"), row.names = F)
```

#Scores binarising for 100 TFs from random forest
```{r  eval=FALSE, echo=FALSE}
#Heatmap of averages for each phenotype
aucell_scores_norm_cell_types<-cell_types_cell_ids
for (x in names(cell_types_cell_ids)){
  aucell_scores_norm_cell_types[[x]]<-aucell_scores_norm[aucell_model_importance_top100,][,cell_types_cell_ids[[x]]]
}

aucell_scores_norm_cell_types_means<-lapply(aucell_scores_norm_cell_types, rowMeans)
aucell_scores_norm_cell_types_means<-as.data.frame(aucell_scores_norm_cell_types_means)

pdf(paste0(analysis_directory,'/figures/aucell_scores_norm_top100_cell_type_average.pdf'),
     width=15,
     height=30)

Heatmap(aucell_scores_norm_cell_types_means,cluster_rows = F,cluster_columns = F, column_labels = names(cell_types))
dev.off()

#Cell type specific distribution (averages of each TF in a cell type)
for (x in names(aucell_scores_norm_cell_types_means)){
  hist(aucell_scores_norm_cell_types_means[[x]], breaks=30, main=x)
}

lapply(aucell_scores_norm_cell_types_means, is.bimodal)
lapply(aucell_scores_norm_cell_types_means, bimodality_coefficient)>0.555

#Use k means to separate each cell type into two groups
aucell_scores_norm_cell_types_means_kmeans<-apply(aucell_scores_norm_cell_types_means,2,kmeans,centers=2, nstart=100)

for (x in names(aucell_scores_norm_cell_types_means_kmeans)){
  aucell_scores_norm_cell_types_means_kmeans[[x]]<-aucell_scores_norm_cell_types_means_kmeans[[x]]$cluster
}

#See what clusters belong to active type
for (x in names(aucell_scores_norm_cell_types_means_kmeans)){
  aucell_scores_norm_cell_types_means_kmeans[[x]]<-split(aucell_scores_norm_cell_types_means_kmeans[[x]],aucell_scores_norm_cell_types_means_kmeans[[x]])
}

min_max<-aucell_scores_norm_cell_types_means_kmeans
for (x in names(aucell_scores_norm_cell_types_means_kmeans)){
  for (y in names(aucell_scores_norm_cell_types_means_kmeans[[x]])){
    h<-aucell_scores_norm_cell_types_means[names(aucell_scores_norm_cell_types_means_kmeans[[x]][[y]]),x]
    hist(h, breaks=30, main=paste0(x,"_",y))
    min_max[[x]][[y]]<-c(min(h),max(h))
  }
}

#Binarize dataframe with cell type averages
aucell_scores_norm_cell_types_means_binarized<-data.frame(matrix(ncol=length(aucell_scores_norm_cell_types_means_kmeans),nrow=nrow(aucell_scores_norm_cell_types_means)))
colnames(aucell_scores_norm_cell_types_means_binarized)=names(aucell_scores_norm_cell_types_means_kmeans)
rownames(aucell_scores_norm_cell_types_means_binarized)=rownames(aucell_scores_norm_cell_types_means)

for (x in names(aucell_scores_norm_cell_types_means_kmeans)[1:2]){
  aucell_scores_norm_cell_types_means_binarized[names(aucell_scores_norm_cell_types_means_kmeans[[x]][[1]]),x]<-1
  aucell_scores_norm_cell_types_means_binarized[names(aucell_scores_norm_cell_types_means_kmeans[[x]][[2]]),x]<-0
}

aucell_scores_norm_cell_types_means_binarized[names(aucell_scores_norm_cell_types_means_kmeans[["exh"]][[2]]),"exh"]<-1
aucell_scores_norm_cell_types_means_binarized[names(aucell_scores_norm_cell_types_means_kmeans[["exh"]][[1]]),"exh"]<-0

Heatmap(as.data.frame(aucell_scores_norm_cell_types_means_binarized),cluster_rows = F,cluster_columns = F, column_labels = names(cell_types))

pdf(paste0(analysis_directory,'/figures/aucell_scores_norm_top100_cell_type_average_binarized.pdf'),
     width=15,
     height=30)

Heatmap(aucell_scores_norm_cell_types_means_binarized,cluster_rows = F,cluster_columns = F, column_labels = names(cell_types))
dev.off()

#Define a threshold to binarize all the cells
cutoff_thresholds<-c()
for (x in names(min_max)){
  to_avg<-c(min_max[[x]][[1]][1],min_max[[x]][[2]][2])
  avg<-mean(to_avg)
  cutoff_thresholds<-append(cutoff_thresholds,avg)
}
names(cutoff_thresholds)<-names(min_max)

#Binarize dataframe with all the cells
aucell_scores_norm_cell_types_binarized<-aucell_scores_norm_cell_types
for (z in names(aucell_scores_norm_cell_types_binarized)){
  t_f<-aucell_scores_norm_cell_types[[z]]>cutoff_thresholds[z]
  for (x in seq(ncol(aucell_scores_norm_cell_types[[z]]))){
    pos<-which(t_f[,x]==T)
    aucell_scores_norm_cell_types_binarized[[z]][pos,x]<-1
    aucell_scores_norm_cell_types_binarized[[z]][-pos,x]<-0
  }
}

aucell_scores_norm_cell_types_binarized<-lapply(aucell_scores_norm_cell_types_binarized,function(x){rowSums(x)/ncol(x)})
aucell_scores_norm_cell_types_binarized<-as.data.frame(aucell_scores_norm_cell_types_binarized)

Heatmap(aucell_scores_norm_cell_types_binarized,cluster_rows = F,cluster_columns = F, column_labels = names(cell_types))

pdf(paste0(analysis_directory,'/figures/aucell_scores_norm_top100_cell_type_binarized_percentage_2.pdf'),
     width=15,
     height=30)

Heatmap(aucell_scores_norm_cell_types_binarized,cluster_rows = F,cluster_columns = F, column_labels = names(cell_types))
dev.off()

write.csv(aucell_scores_norm_cell_types_binarized,paste0(analysis_directory,"/","aucell_scores_norm_cell_types_binarized.csv"), row.names = F)
```

#Assign cell type to each TF
```{r echo=FALSE, eval=FALSE}
#Find max expression in each TF
aucell_scores_norm_cell_types_binarized_max<-apply(aucell_scores_norm_cell_types_binarized,1,max)
aucell_scores_norm_cell_types_binarized_max_cell_type<-aucell_scores_norm_cell_types_binarized_max
for (x in names(aucell_scores_norm_cell_types_binarized_max)){
  aucell_scores_norm_cell_types_binarized_max_cell_type[x]<-colnames(aucell_scores_norm_cell_types_binarized)[which(aucell_scores_norm_cell_types_binarized[x,]==aucell_scores_norm_cell_types_binarized_max[x])]
}

#Order them alphabetically
aucell_scores_norm_cell_types_binarized_max_cell_type<-aucell_scores_norm_cell_types_binarized_max_cell_type[order(names(aucell_scores_norm_cell_types_binarized_max_cell_type))]

#Overview
table(aucell_scores_norm_cell_types_binarized_max_cell_type)

#Make a list for each cell type
acuell_scores_max_expr_assignment<-split(names(aucell_scores_norm_cell_types_binarized_max_cell_type),aucell_scores_norm_cell_types_binarized_max_cell_type)

#Export
for (x in names(acuell_scores_max_expr_assignment)){
  write.csv(acuell_scores_max_expr_assignment[[x]],paste0(analysis_directory,"/","acuell_scores_max_expr_assignment/",x,".csv"), row.names = F)
}

write.csv(aucell_scores_norm_cell_types_binarized_max_cell_type,paste0(analysis_directory,"/","aucell_scores_norm_cell_types_binarized_max_cell_type.csv"), row.names = F)

write.csv(names(aucell_scores_norm_cell_types_binarized_max_cell_type),paste0(analysis_directory,"/","aucell_scores_norm_cell_types_binarized_max_cell_type_names.csv"), row.names = F)
```

#Import AUCell data
```{r}
aucell_model_importance_top100<-read.csv(paste0(analysis_directory,"/aucell_model_importance_top100.csv"))[,1]

acuell_scores_max_expr_assignment_file_names<-list.files(paste0(analysis_directory,"/","acuell_scores_max_expr_assignment"))
acuell_scores_max_expr_assignment<-list()
for (x in seq_along(acuell_scores_max_expr_assignment_file_names)){
  acuell_scores_max_expr_assignment[[x]]<-read.csv(paste0(analysis_directory,"/","acuell_scores_max_expr_assignment/",acuell_scores_max_expr_assignment_file_names[x]))[,1]
}
names(acuell_scores_max_expr_assignment)<-sub(".csv*.", "", acuell_scores_max_expr_assignment_file_names)

aucell_scores_norm_cell_types_binarized_max_cell_type<-read.csv(paste0(analysis_directory,"/","aucell_scores_norm_cell_types_binarized_max_cell_type.csv"))[,1]
names(aucell_scores_norm_cell_types_binarized_max_cell_type)<-read.csv(paste0(analysis_directory,"/","aucell_scores_norm_cell_types_binarized_max_cell_type_names.csv"))[,1]
```

#Hierarchical clustering of binarized scores to compare our cell type/TF assignment
```{r echo=FALSE, eval=FALSE}
#Cluster
dd <- dist(aucell_scores_norm_cell_types_binarized, method = "euclidean")
hc <- hclust(dd, method = "ward.D2")

#Split into 3 groups
acuell_scores_hclust_3g_assignment<-split(names(cutree(hc, k = 3))[order(names(cutree(hc, k = 3)))],cutree(hc, k = 3))

#Compare the assignments
max_expr_hclust_3g_overlap<-vector("list",length(acuell_scores_hclust_3g_assignment))
names(max_expr_hclust_3g_overlap)<-names(acuell_scores_hclust_3g_assignment)
for (x in names(acuell_scores_hclust_3g_assignment)){
  best_match<-c()
  for (y in names(acuell_scores_max_expr_assignment)){
    match<-1-length(setdiff(acuell_scores_hclust_3g_assignment[[x]],acuell_scores_max_expr_assignment[[y]]))/length(acuell_scores_hclust_3g_assignment[[x]])
    best_match<-append(best_match, match)
  }
  max_expr_hclust_3g_overlap[[x]]<-best_match
}

#Split into 2 groups
acuell_scores_hclust_2g_assignment<-split(names(cutree(hc, k = 2))[order(names(cutree(hc, k = 2)))],cutree(hc, k = 2))
max_expr_hclust_2g_overlap<-vector("list",length(acuell_scores_hclust_2g_assignment))
names(max_expr_hclust_2g_overlap)<-names(acuell_scores_hclust_2g_assignment)
for (x in names(acuell_scores_hclust_2g_assignment)){
  best_match<-c()
  for (y in names(acuell_scores_max_expr_assignment)){
    match<-1-length(setdiff(acuell_scores_hclust_2g_assignment[[x]],acuell_scores_max_expr_assignment[[y]]))/length(acuell_scores_hclust_2g_assignment[[x]])
    best_match<-append(best_match, match)
  }
  max_expr_hclust_2g_overlap[[x]]<-best_match
}
```

#Create a network and communities using 90% as scenic filter and 100 TFs from RF
```{r}
#Select only interactions that are among top 100 TFs
frequency_summary_top100<-frequency_summary[which(frequency_summary$TF %in% aucell_model_importance_top100),]
frequency_summary_top100<-frequency_summary_top100[which(frequency_summary_top100$target %in% aucell_model_importance_top100),]
frequency_summary_top100<-frequency_summary_top100[which(frequency_summary_top100$frequency>=45),]
frequency_summary_top100<-frequency_summary_top100[,c(1,2,6)]

vertices.df<-data.frame(unique(c(frequency_summary_top100$TF,frequency_summary_top100$target))[order(unique(c(frequency_summary_top100$TF,frequency_summary_top100$target)))])
vertices.df["most_expressed_in"]<-aucell_scores_norm_cell_types_binarized_max_cell_type[names(aucell_scores_norm_cell_types_binarized_max_cell_type) %in% vertices.df[,1]]

#Look how many of these interactions are confirmed by cistrome and frequency
frequency_confirmed_interactions_summary_top100<-frequency_confirmed_interactions_summary[which(frequency_confirmed_interactions_summary$TF %in% aucell_model_importance_top100),]
frequency_confirmed_interactions_summary_top100<-frequency_confirmed_interactions_summary_top100[which(frequency_confirmed_interactions_summary_top100$target %in% aucell_model_importance_top100),]
frequency_confirmed_interactions_summary_top100<-frequency_confirmed_interactions_summary_top100[which(frequency_confirmed_interactions_summary_top100$frequency>=45),]

#Add confirmed interactions column to the frequency_summary_top100 dataframe
frequency_summary_top100["confirmed_interactions"]<-F
for (x in seq(nrow(frequency_confirmed_interactions_summary_top100))){
  tf_row<-which(frequency_summary_top100$TF==frequency_confirmed_interactions_summary_top100[x,]$TF)
  target_row<-which(frequency_summary_top100$target==frequency_confirmed_interactions_summary_top100[x,]$target)
  pos<-tf_row[which(tf_row %in% target_row)]
  frequency_summary_top100[pos,"confirmed_interactions"]<-T
}

#Look how many of our nodes overlap with the paper
paper_top100_overlap<-paper_nodes[paper_nodes %in% unique(c(frequency_summary_top100$TF,frequency_summary_top100$target))]

# Importing to igraph
g <- graph_from_data_frame(d = frequency_summary_top100, directed = TRUE, vertices = vertices.df)
V(g)$degree <- igraph::degree(g)

# Select vertices with highest degrees
v.degree <- igraph::degree(g)
v.sorted <- sort(v.degree, decreasing = TRUE)
v.sorted<-names(v.sorted)

#Color nodes according to their highest expression
colrs <- c("#FB8072","#80B1D3","#BEBADA")
my_color<-colrs[as.numeric(as.factor(V(g)$most_expressed_in))]

#Add weight to edges
E(g)$weight<-frequency_summary_top100$NIS

g <- induced_subgraph(g, v = v.sorted)
l <- layout_with_fr(g)

pdf(paste0(analysis_directory,'/figures/frequency_90_interactions_top100_plot.pdf'),
     width=15,
     height=15)
plot(g, 
     layout=l,
     edge.arrow.size=0.25,
     edge.color=c("grey","dark red")[as.numeric(as.factor(E(g)$confirmed_interactions))],
     vertex.size=5,
     vertex.label.cex=0.4,
     vertex.color=my_color,
     edge.width=E(g)$weight*3,
     vertex.frame.color='white')
legend(x=-1, y=-0.5, c("Exhausted","Memory", "Transition"), pch=21,
       col="#777777", pt.bg=colrs, pt.cex=2, cex=1.5, bty="n", ncol=1)
dev.off()
```

#Create table for cytoscape
```{r echo=FALSE, eval=FALSE}
#Louvain_clustering
louvain_clustering_res_0.5<-cluster_louvain(as.undirected(g),weight=frequency_summary_top100$NIS, resolution = 0.5)

#Get the communities
louvain_clustering_res_0.5_communities<-louvain_clustering_res_0.5$membership
names(louvain_clustering_res_0.5_communities)<-louvain_clustering_res_0.5$names
louvain_clustering_res_0.5_communities<-split(names(louvain_clustering_res_0.5_communities),louvain_clustering_res_0.5_communities)

#Nodes table
cytoscape_nodes<-vertices.df
colnames(cytoscape_nodes)[1]<-"nodes"
cytoscape_nodes["group"]<-0

for (x in names(louvain_clustering_res_0.5_communities)){
  for (y in louvain_clustering_res_0.5_communities[[x]]){
    pos<-which(cytoscape_nodes$nodes==y)
    cytoscape_nodes[pos,"group"]<-x
  }
}

#Interactions table
cytoscape_interactions<-frequency_summary_top100

#Merge both tables
cytoscape<-cytoscape_interactions

#Get information for TFs and targets
cytoscape["TF_most_expressed_in"]<-"none"
cytoscape["TF_group"]<-0
cytoscape["target_most_expressed_in"]<-"none"
cytoscape["target_group"]<-0

for (x in seq(nrow(cytoscape))){
  pos<-which(cytoscape_nodes$nodes==cytoscape$TF[x])
  cytoscape[x,"TF_most_expressed_in"]<-cytoscape_nodes[pos,"most_expressed_in"]
  cytoscape[x,"TF_group"]<-cytoscape_nodes[pos,"group"]
  
  pos2<-which(cytoscape_nodes$nodes==cytoscape$target[x])
  cytoscape[x,"target_most_expressed_in"]<-cytoscape_nodes[pos2,"most_expressed_in"]
  cytoscape[x,"target_group"]<-cytoscape_nodes[pos2,"group"]
}

#Reorder columns
cytoscape<-cytoscape[,c(1,5,6,2,7,8,3,4)]

cytoscape["TF_group"]<-as.integer(cytoscape$TF_group)
cytoscape["target_group"]<-as.integer(cytoscape$target_group)

#Save the table
write.table(cytoscape, file=paste0(analysis_directory,'/cytoscape/Input/cytoscape_05.tsv'), quote=FALSE, sep='\t', row.names = F)
```

#Keep only nodes and interactions from paper
```{r}
#Fuse JUN and FOS nodes
frequency_summary_top100["TF"]<-gsub("JUNB|JUND|JUN|FOSB|FOS","JUN-FOS",frequency_summary_top100$TF)
frequency_summary_top100["target"]<-gsub("JUNB|JUND|JUN|FOSB|FOS","JUN-FOS",frequency_summary_top100$target)

paper_top100_overlap<-unique(gsub("JUN|FOS","JUN-FOS",paper_top100_overlap))

#Create dataframe with only paper overlaps
frequency_summary_top100_paper_tf<-frequency_summary_top100[frequency_summary_top100$TF %in% paper_top100_overlap,]
frequency_summary_top100_paper_target<-frequency_summary_top100[!frequency_summary_top100$TF %in% paper_top100_overlap,][frequency_summary_top100[!frequency_summary_top100$TF %in% paper_top100_overlap,]$target %in% paper_top100_overlap,]

frequency_summary_top100_paper<-rbind(frequency_summary_top100_paper_tf,frequency_summary_top100_paper_target)

#Interactions we miss out on
frequency_summary_top100_paper_nodes<-sort(unique(c(frequency_summary_top100_paper$TF,frequency_summary_top100_paper$target)))
frequency_summary_top100_paper_nodes_miss<-frequency_summary_top100_paper_nodes[-which(frequency_summary_top100_paper_nodes %in% paper_top100_overlap)]

tf<-which(frequency_summary_top100$TF %in% frequency_summary_top100_paper_nodes_miss)
target<-which(frequency_summary_top100$target %in% frequency_summary_top100_paper_nodes_miss)
pos<-target %in% tf

frequency_summary_top100_paper_interactions_miss<-frequency_summary_top100[target[pos],]

#Unite the existing and the missing interactions
frequency_summary_top100_paper<-rbind(frequency_summary_top100_paper,frequency_summary_top100_paper_interactions_miss)

#Remove self regulation
remove<-c()
for (x in seq(nrow(frequency_summary_top100_paper))){
  if(frequency_summary_top100_paper$TF[x]==frequency_summary_top100_paper$target[x]){
    remove<-append(remove,x)
  }
}

frequency_summary_top100_paper<-frequency_summary_top100_paper[-remove,]
frequency_summary_top100_paper<-frequency_summary_top100_paper[order(frequency_summary_top100_paper$TF),]

#Create all interactions
frequency_summary_top100_paper_interactions<-c()
for(x in seq(nrow(frequency_summary_top100_paper))){
    frequency_summary_top100_paper_interactions<-append(frequency_summary_top100_paper_interactions,paste0(frequency_summary_top100_paper$TF[x],"->",frequency_summary_top100_paper$target[x]))
}

#Find duplicates, remove them and assign new NIS
duplicate_interactions<-unique(frequency_summary_top100_paper_interactions[duplicated(frequency_summary_top100_paper_interactions)])

new_nis<-vector("list",length(duplicate_interactions))
names(new_nis)<-duplicate_interactions
for(x in duplicate_interactions){
  pos<-grep(x,frequency_summary_top100_paper_interactions)
  new_nis[[x]]<-mean(frequency_summary_top100_paper[pos,]$NIS)
}

frequency_summary_top100_paper_interactions_nis<-frequency_summary_top100_paper$NIS
names(frequency_summary_top100_paper_interactions_nis)<-frequency_summary_top100_paper_interactions
frequency_summary_top100_paper_interactions_nis<-frequency_summary_top100_paper_interactions_nis[-which(duplicated(frequency_summary_top100_paper_interactions))]
frequency_summary_top100_paper_interactions_nis[duplicate_interactions]<-unlist(new_nis)

frequency_summary_top100_paper<-frequency_summary_top100_paper[-which(duplicated(frequency_summary_top100_paper_interactions)),]
frequency_summary_top100_paper["NIS"]<-frequency_summary_top100_paper_interactions_nis

#Introduce lost confirmed interactions
frequency_confirmed_interactions_summary_top100_paper<-frequency_confirmed_interactions_summary_top100
frequency_confirmed_interactions_summary_top100_paper["TF"]<-gsub("JUNB|JUND|JUN|FOSB|FOS","JUN-FOS",frequency_confirmed_interactions_summary_top100_paper$TF)
frequency_confirmed_interactions_summary_top100_paper["target"]<-gsub("JUNB|JUND|JUN|FOSB|FOS","JUN-FOS",frequency_confirmed_interactions_summary_top100_paper$target)

confirmed_interactions_paper<-c()
for (x in seq(nrow(frequency_confirmed_interactions_summary_top100_paper))){
  tfs<-which(frequency_summary_top100_paper$TF==frequency_confirmed_interactions_summary_top100_paper$TF[x])
  targets<-which(frequency_summary_top100_paper$target==frequency_confirmed_interactions_summary_top100_paper$target[x])
  pos<-tfs[tfs %in% targets]
  if(length(pos)!=0){
    confirmed_interactions_paper<-append(confirmed_interactions_paper,pos)
  }
}

frequency_summary_top100_paper[confirmed_interactions_paper,"confirmed_interactions"]<-T

#Modify JUN-FOS vertices to get "most_expressed in" right
vertices.df_paper<-vertices.df
vertices.df_paper[,1]<-gsub("JUNB|JUND|JUN|FOSB|FOS","JUN-FOS",vertices.df_paper[,1])
vertices.df_paper<-vertices.df_paper[-which(duplicated(vertices.df_paper[,1])),]

vertices.df_paper<-vertices.df_paper[vertices.df_paper[,1] %in% unique(c(frequency_summary_top100_paper$TF,frequency_summary_top100_paper$target)), ]
colnames(vertices.df_paper)[1]<-"nodes"

#Compute Louvain clustering and add group number to the vertices.df_paper
g_paper_overlap <- graph_from_data_frame(d = frequency_summary_top100_paper, directed = T, vertices = vertices.df_paper)

V(g_paper_overlap)$degree <- igraph::degree(g_paper_overlap)

# Select vertices with highest degrees
v.degree <- igraph::degree(g_paper_overlap)
v.sorted <- sort(v.degree, decreasing = TRUE)
v.sorted<-names(v.sorted)

#Color nodes according to their highest expression
colrs <- c("#FB8072","#80B1D3","#BEBADA")
my_color<-colrs[as.numeric(as.factor(V(g_paper_overlap)$most_expressed_in))]

#Add weight to edges
E(g_paper_overlap)$weight<-frequency_summary_top100_paper$NIS

g_paper_overlap<- induced_subgraph(g_paper_overlap, v = v.sorted)
l <- layout_with_fr(g_paper_overlap)

pdf(paste0(analysis_directory,"/figures/RF_paper_overlap_TFs.pdf"),
     width=15,
     height=15)
plot(g_paper_overlap, 
     layout=l,
     edge.arrow.size=0.25,
     edge.color=c("grey","dark red")[as.numeric(as.factor(E(g_paper_overlap)$confirmed_interactions))],
     vertex.size=5,
     vertex.label.cex=0.4,
     vertex.color=my_color,
     edge.width=E(g_paper_overlap)$weight*3,
     vertex.frame.color='white')
legend(x=-1, y=-0.5, c("Exhausted","Memory", "Transition"), pch=21,
       col="#777777", pt.bg=colrs, pt.cex=2, cex=1.5, bty="n", ncol=1)
dev.off()
```

#Create cytoscape expotr file for cytoscape_paper_overlap
```{r eval=FALSE, echo=FALSE}
louvain_clustering_paper<-cluster_louvain(as.undirected(g_paper_overlap),weight=frequency_summary_top100_paper$NIS, resolution = 0.35)
louvain_clustering_paper_communities<-louvain_clustering_paper$membership
names(louvain_clustering_paper_communities)<-louvain_clustering_paper$names
louvain_clustering_paper_communities<-split(names(louvain_clustering_paper_communities),louvain_clustering_paper_communities)

vertices.df_paper["group"]<-0

for (x in names(louvain_clustering_paper_communities)){
  for (y in louvain_clustering_paper_communities[[x]]){
    pos<-which(vertices.df_paper$nodes==y)
    vertices.df_paper[pos,"group"]<-x
  }
}

#Add TF and target missing information
cytoscape_paper_overlap<-frequency_summary_top100_paper

cytoscape_paper_overlap["TF_most_expressed_in"]<-"none"
cytoscape_paper_overlap["TF_group"]<-0
cytoscape_paper_overlap["target_most_expressed_in"]<-"none"
cytoscape_paper_overlap["target_group"]<-0

for (x in seq(nrow(cytoscape_paper_overlap))){
  pos<-which(vertices.df_paper$nodes==cytoscape_paper_overlap$TF[x])
  cytoscape_paper_overlap[x,"TF_most_expressed_in"]<-vertices.df_paper[pos,"most_expressed_in"]
  cytoscape_paper_overlap[x,"TF_group"]<-vertices.df_paper[pos,"group"]
  
  pos2<-which(vertices.df_paper$nodes==cytoscape_paper_overlap$target[x])
  cytoscape_paper_overlap[x,"target_most_expressed_in"]<-vertices.df_paper[pos2,"most_expressed_in"]
  cytoscape_paper_overlap[x,"target_group"]<-vertices.df_paper[pos2,"group"]
}

cytoscape_paper_overlap<-cytoscape_paper_overlap[,c(1,5,6,2,7,8,3,4)]

#Save the table
write.table(cytoscape_paper_overlap, file=paste0(analysis_directory,'/cytoscape/Input/cytoscape_paper_overlap.tsv'), quote=FALSE, sep='\t', row.names = F)
```

#Format Bolouri paper interactions table
```{r}
#Open file
setwd(data_directory)
bolouri_paper_interactions<-read.delim("Bolouri_paper_interactions.txt")
colnames(bolouri_paper_interactions)[1:2]<-c("TF","target")

#Unify nomenclature
bolouri_paper_interactions["TF"]<-gsub("AP1","JUN-FOS",bolouri_paper_interactions$TF)
bolouri_paper_interactions["TF"]<-gsub("BLIMP-1","PRDM1",bolouri_paper_interactions$TF)
bolouri_paper_interactions["TF"]<-gsub("NFkB","NFKB1",bolouri_paper_interactions$TF)
bolouri_paper_interactions["TF"]<-gsub("EZH2/PRC2","EZH2",bolouri_paper_interactions$TF)

bolouri_paper_interactions["target"]<-gsub("AP1","JUN-FOS",bolouri_paper_interactions$target)
bolouri_paper_interactions["target"]<-gsub("BLIMP-1","PRDM1",bolouri_paper_interactions$target)
bolouri_paper_interactions["target"]<-gsub("NFkB","NFKB1",bolouri_paper_interactions$target)
bolouri_paper_interactions["target"]<-gsub("EZH2/PRC2","EZH2",bolouri_paper_interactions$target)

#Select only interactions that have as TF or target an overlapping node
bolouri_paper_interactions_overlap<-rbind(bolouri_paper_interactions[which(bolouri_paper_interactions$TF %in% paper_top100_overlap),],bolouri_paper_interactions[which(bolouri_paper_interactions$target %in% paper_top100_overlap),])

#Interactions we miss out on
bolouri_paper_interactions_overlap_nodes<-sort(unique(c(bolouri_paper_interactions_overlap$TF,bolouri_paper_interactions_overlap$target)))
bolouri_paper_interactions_overlap_nodes_miss<-bolouri_paper_interactions_overlap_nodes[-which(bolouri_paper_interactions_overlap_nodes %in% paper_top100_overlap)]

tf<-which(bolouri_paper_interactions$TF %in% bolouri_paper_interactions_overlap_nodes_miss)
target<-which(bolouri_paper_interactions$target %in% bolouri_paper_interactions_overlap_nodes_miss)
pos<-target %in% tf

bolouri_paper_interactions_overlap_interactions_miss<-bolouri_paper_interactions[target[pos],]

#Unite the identified and missed interactions
bolouri_paper_interactions_overlap<-rbind(bolouri_paper_interactions_overlap,bolouri_paper_interactions_overlap_interactions_miss)

#Create all interactions
bolouri_paper_interactions_overlap<-bolouri_paper_interactions_overlap[order(bolouri_paper_interactions_overlap$TF),]

bolouri_paper_interactions_overlap_interactions<-c()
for(x in seq(nrow(bolouri_paper_interactions_overlap))){
    bolouri_paper_interactions_overlap_interactions<-append(bolouri_paper_interactions_overlap_interactions,paste0(bolouri_paper_interactions_overlap$TF[x],"->",bolouri_paper_interactions_overlap$target[x]))
}

#Remove duplicates
rownames(bolouri_paper_interactions_overlap)<-seq(nrow(bolouri_paper_interactions_overlap))

bolouri_paper_interactions_overlap<-bolouri_paper_interactions_overlap[-which(duplicated(bolouri_paper_interactions_overlap_interactions)),]

#Look for further nomenclature differences
tf_nomenclature<-names(paper_substitutions)[names(paper_substitutions) %in% bolouri_paper_interactions_overlap$TF]

unlist(paper_substitutions[tf_nomenclature]) %in% vertices.df_paper$nodes 

names(paper_substitutions)[names(paper_substitutions) %in% bolouri_paper_interactions_overlap$target]
```

#Create new cytoscape df to represent overlap between Bolouri paper and 82 RF TF network
```{r}
#Import required data
cytoscape_paper_overlap<-read.table(paste0(analysis_directory,"/cytoscape/Input/cytoscape_paper_overlap.tsv"), sep='\t', header=T)

#Remove rows that dont contain TFs
rownames(bolouri_paper_interactions_overlap)<-seq(nrow(bolouri_paper_interactions_overlap))
bolouri_paper_interactions_overlap<-bolouri_paper_interactions_overlap[-c(36,37,38),]
bolouri_paper_interactions_overlap<-bolouri_paper_interactions_overlap[order(bolouri_paper_interactions_overlap$TF),]
rownames(bolouri_paper_interactions_overlap)<-seq(nrow(bolouri_paper_interactions_overlap))
rownames(cytoscape_paper_overlap)<-seq(nrow(cytoscape_paper_overlap))

#Split the bolouri_paper_interactions_overlap in interactions that we already have in our network and the new ones
common_interactions<-c()
for (x in seq(nrow(cytoscape_paper_overlap))){
  tfs<-which(bolouri_paper_interactions_overlap$TF==cytoscape_paper_overlap$TF[x])
  targets<-which(bolouri_paper_interactions_overlap$target==cytoscape_paper_overlap$target[x])
  pos<-which(tfs %in% targets)
  if(length(pos!=0)){
    common_interactions<-append(common_interactions,x)
  }
}

#Mark the common interaction
bolouri_RF_fusion<-cytoscape_paper_overlap
bolouri_RF_fusion["RF"]<-T
bolouri_RF_fusion["paper"]<-F

bolouri_paper_interactions_overlap<-bolouri_paper_interactions_overlap[,c(1,2)]
bolouri_paper_interactions_overlap["RF"]<-F
bolouri_paper_interactions_overlap["paper"]<-T
bolouri_paper_interactions_overlap["NIS"]<-1
bolouri_paper_interactions_overlap["confirmed_interactions"]<-F

#Assign "most_expressed_in" column
vertices.df_fusion<-vertices.df_paper
rownames(vertices.df_fusion)<-seq(nrow(vertices.df_fusion))

nodes_to_add<-unique(c(bolouri_paper_interactions_overlap$TF,bolouri_paper_interactions_overlap$target))[!unique(c(bolouri_paper_interactions_overlap$TF,bolouri_paper_interactions_overlap$target)) %in% vertices.df_fusion$nodes]
new_rows<-gsub(" ",",",seq(nrow(vertices.df_fusion)+1,nrow(vertices.df_fusion)+length(nodes_to_add)))
vertices.df_fusion[new_rows,]<-nodes_to_add
nodes_to_add_expr<-c("mem","mem","mem","rec","rec","rec","mem","mem","mem","exh","exh","exh","mem","mem","exh","p-complex","mem","rec","mem","exh","exh","rec","rec","rec","rec")
vertices.df_fusion[new_rows,"most_expressed_in"]<-nodes_to_add_expr

bolouri_paper_interactions_overlap["TF_most_expressed_in"]<-"none"
bolouri_paper_interactions_overlap["target_most_expressed_in"]<-"none"

for (x in seq(nrow(bolouri_paper_interactions_overlap))){
  pos<-which(vertices.df_fusion$nodes==bolouri_paper_interactions_overlap$TF[x])
  bolouri_paper_interactions_overlap[x,"TF_most_expressed_in"]<-vertices.df_fusion[pos,"most_expressed_in"]
  
  pos2<-which(vertices.df_fusion$nodes==bolouri_paper_interactions_overlap$target[x])
  bolouri_paper_interactions_overlap[x,"target_most_expressed_in"]<-vertices.df_fusion[pos2,"most_expressed_in"]
}

#Create igraph to represent the combined network
igraph_fusion<-rbind(bolouri_RF_fusion[,c(1,4,7)],bolouri_paper_interactions_overlap[,c(1,2,5)])
rownames(igraph_fusion)<-seq(nrow(igraph_fusion))

g_fusion <- graph_from_data_frame(d = igraph_fusion, directed = T, vertices = vertices.df_fusion)

V(g_fusion)$degree <- igraph::degree(g_fusion)

# Select vertices with highest degrees
v.degree <- igraph::degree(g_fusion)
v.sorted <- sort(v.degree, decreasing = TRUE)
v.sorted<-names(v.sorted)

#Color nodes according to their highest expression
colrs <- c("#FB8072","#80B1D3","#AFE1AF","#EDD94C","#BEBADA")
my_color<-colrs[as.numeric(as.factor(V(g_fusion)$most_expressed_in))]

#Add weight to edges
E(g_fusion)$weight<-igraph_fusion$NIS

g_fusion<- induced_subgraph(g_fusion, v = v.sorted)
l <- layout_with_fr(g_fusion)

pdf(paste0(analysis_directory,"/figures/bolouri_RF_fusion.pdf"),
     width=15,
     height=15)
plot(g_fusion, 
     layout=l,
     edge.arrow.size=0.25,
     vertex.size=5,
     vertex.label.cex=0.4,
     vertex.color=my_color,
     edge.width=E(g_fusion)$weight*3,
     vertex.frame.color='white')
legend(x=-1, y=-0.5, c("Exhausted","Memory","Protein Complex","Receptors","Transition"), pch=21,
       col="#777777", pt.bg=colrs, pt.cex=2, cex=1.5, bty="n", ncol=1)
dev.off()
```

#Create cytoscape export file for cytoscape_bolouri_RF_fusion
```{r echo=FALSE, eval=FALSE}
#Louvain clustering
louvain_clustering_fusion<-cluster_louvain(as.undirected(g_fusion),weight=igraph_fusion$NIS, resolution =0.6)
louvain_clustering_fusion_communities<-louvain_clustering_fusion$membership
names(louvain_clustering_fusion_communities)<-louvain_clustering_fusion$names
louvain_clustering_fusion_communities<-split(names(louvain_clustering_fusion_communities),louvain_clustering_fusion_communities)

vertices.df_fusion["group"]<-0

for (x in names(louvain_clustering_fusion_communities)){
  for (y in louvain_clustering_fusion_communities[[x]]){
    pos<-which(vertices.df_fusion$nodes==y)
    vertices.df_fusion[pos,"group"]<-x
  }
}

#Fuse the two tables
bolouri_paper_interactions_overlap["TF_group"]<-0
bolouri_paper_interactions_overlap["target_group"]<-0

bolouri_RF_fusion<-rbind(bolouri_RF_fusion,bolouri_paper_interactions_overlap)

#Add the group informatoon for all the nodes
for (x in seq(nrow(bolouri_RF_fusion))){
  pos<-which(vertices.df_fusion$nodes==bolouri_RF_fusion$TF[x])
  bolouri_RF_fusion[x,"TF_group"]<-vertices.df_fusion[pos,"group"]
  
  pos2<-which(vertices.df_fusion$nodes==bolouri_RF_fusion$target[x])
  bolouri_RF_fusion[x,"target_group"]<-vertices.df_fusion[pos2,"group"]
}

#Save the table
write.table(bolouri_RF_fusion, file=paste0(analysis_directory,'/cytoscape/Input/cytoscape_bolouri_RF_fusion.tsv'), quote=FALSE, sep='\t', row.names = F)
```

#Bonesis Toy
```{r}
#Import edges
bonesis_toy_edges<-read.csv(paste0(analysis_directory,"/cytoscape/Output/new_bonesis_toy_edges.csv"),header=T)[,3]
bonesis_toy_tf<-sub(" .*", "", bonesis_toy_edges)
bonesis_toy_target<-sub(".* ", "", bonesis_toy_edges)
bonesis_toy_tf<-sub("CD3,", "CD3, TCR, CD8, CD28", bonesis_toy_tf)
bonesis_toy_target<-sub("CD28", "CD3, TCR, CD8, CD28", bonesis_toy_target)

bonesis_toy_interactions<-data.frame(matrix(nrow=length(bonesis_toy_edges),ncol=3))
colnames(bonesis_toy_interactions)<-c("TF","target","Importance")
bonesis_toy_interactions["TF"]<-bonesis_toy_tf
bonesis_toy_interactions["target"]<-bonesis_toy_target

#Import nodes
bonesis_toy_nodes<-read.csv(paste0(analysis_directory,"/cytoscape/Output/new_bonesis_toy_nodes.csv"),header=T)[,c(1,2,3)]

#Assign the importance
bonesis_toy_interactions["Importance"]<-bolouri_paper_interactions[find_same_interactions_dfs(bolouri_paper_interactions,bonesis_toy_interactions),]$Interaction

#Prepare the datdaframe for the Bonesis
for (x in seq_along(bonesis_toy_interactions$Importance)){
  if(bonesis_toy_interactions$Importance[x]=="inhibits"){
    bonesis_toy_interactions[x,"Importance"]<-1*(-1)
  }else{bonesis_toy_interactions[x,"Importance"]<-1}
}

bonesis_toy_python<-c()
for (x in seq(nrow(bonesis_toy_interactions))){
  bonesis_toy_python<-append(bonesis_toy_python,paste0("(",bonesis_toy_interactions[x,1],",",bonesis_toy_interactions[x,2],",dict(sign=",bonesis_toy_interactions[x,3],")),"))
}

write.table(bonesis_toy_python, file=paste0(analysis_directory,'/bonesis_toy_python.tsv'), quote=FALSE, sep='\t', row.names = F)

```

#Cell state dataframe for Bonesis: Bolouri
```{r}
#Get raw_input table
raw_input<-read.csv("/media/ag-cherrmann/cramirez/tcd8ExscSeq/data/maike2020/nina_thimme_raw_counts.csv",header=T, row.names=1)

#Read cell annotations
setwd(data_directory)
cell_annotations<-read.xlsx("nina_annotations.xlsx")

#Remove RNA genes
raw_input<-t(as.data.frame(raw_input))
raw_input<-raw_input[,17:dim(raw_input)[2]]

#Remove chromosme tags and duplicates
genes<-gsub("\\_.*","",colnames(raw_input))
remove<-which(duplicated(genes))
genes<-genes[-remove] 
raw_input<-raw_input[,-remove]
colnames(raw_input)<-genes
raw_input<-as.data.frame(raw_input)

#Keep only cells with annotations
raw_input<-raw_input[cell_annotations$CELLID,]

#Dotplot based on new_bonesis_toy
bonesis_toy_tfs<-bonesis_toy_nodes$name[2:length(bonesis_toy_nodes$name)]
bonesis_toy_tfs<-bonesis_toy_tfs[-12]
bonesis_toy_tfs<-bonesis_toy_tfs[-3]

bonesis_toy_tfs<-gsub("TCF-1","HNF1A",bonesis_toy_tfs)
bonesis_toy_tfs<-gsub("CD3, TCR, CD8, CD28","CD28",bonesis_toy_tfs)
bonesis_toy_tfs<-c(bonesis_toy_tfs,"FCER1G")
bonesis_toy_tfs<-gsub("PD-1","PDCD1",bonesis_toy_tfs)
bonesis_toy_tfs<-gsub("CTLA-4","CTLA4",bonesis_toy_tfs)
bonesis_toy_tfs<-gsub("IL12-R","IL12RB1",bonesis_toy_tfs)

dot_plot_input<-as.data.frame(t(raw_input))

cell_code<-seq(length(cell_annotations$TYPE))
dot_plot_code<-c()
for(x in seq_along(cell_code)){
  dot_plot_code[x]<-paste0(cell_annotations$TYPE[x],"_",cell_code[x])
}
colnames(dot_plot_input)<-dot_plot_code

dot_plot_seurat <- CreateSeuratObject(counts = dot_plot_input, project = "cell_exh", min.cells = 0, min.features = 0)
dot_plot_seurat<-NormalizeData(dot_plot_seurat, normalization.method = "LogNormalize", scale.factor = 10000)
all.genes <- rownames(dot_plot_seurat)
dot_plot_seurat <- ScaleData(dot_plot_seurat, features = all.genes)

pdf(paste0(analysis_directory,'/figures/dot_plot_bonesis.pdf'),
     width=15,
     height=7)
DotPlot(dot_plot_seurat, features = bonesis_toy_tfs,cols = c("blue", "red"), dot.scale = 20) + RotatedAxis()+ ggplot2::scale_colour_gradient2(high = "#ff0000", mid = "#FFFFFF", low = "#0000FF")
dev.off()

#Define cell states
cell_states_dot_plot<-data.frame(matrix(nrow=length(cell_types),ncol=nrow(dot_plot_input)))
rownames(cell_states_dot_plot)<-names(cell_types)
colnames(cell_states_dot_plot)<-rownames(dot_plot_input)
cell_states_dot_plot$BACH2<-c(1,NA,NA)
cell_states_dot_plot$BCL6<-NA
cell_states_dot_plot$CD28<-c(1,0,NA)
cell_states_dot_plot$CTLA4<-c(NA,0,1)
#cell_states_dot_plot$EOMES<-c(0,NA,1)
cell_states_dot_plot$EZH2<-c(NA,NA,1)
cell_states_dot_plot$FCER1G<-NA
cell_states_dot_plot$FOXO1<-c(1,0,NA)
cell_states_dot_plot$HNF1A<-NA
cell_states_dot_plot$ID3<-NA
#cell_states_dot_plot$IL12RB1<-c(NA,NA,1)
cell_states_dot_plot$NFATC1<-c(1,NA,NA)
#cell_states_dot_plot$NFATC2<-c(0,NA,NA)
cell_states_dot_plot$PDCD1<-c(NA,0,1)
cell_states_dot_plot$PRDM1<-c(0,NA,1)
```

#Cell state dataframe for Bonesis: Bolouri + Scenic
```{r}
#Import edges
bonesis_toy_edges<-read.csv(paste0(analysis_directory,"/cytoscape/Output/new_bonesis_toy+scenic_edges.csv"),header=T)[,c(3,5,6)]
bonesis_toy_tf<-sub(" .*", "", bonesis_toy_edges$name)
bonesis_toy_target<-sub(".* ", "", bonesis_toy_edges$name)
bonesis_toy_tf<-sub("CD3,", "CD3, TCR, CD8, CD28", bonesis_toy_tf)
bonesis_toy_target<-sub("CD28", "CD3, TCR, CD8, CD28", bonesis_toy_target)

bonesis_toy_interactions<-data.frame(matrix(nrow=length(bonesis_toy_edges$name),ncol=3))
colnames(bonesis_toy_interactions)<-c("TF","target","Importance")
bonesis_toy_interactions["TF"]<-bonesis_toy_tf
bonesis_toy_interactions["target"]<-bonesis_toy_target
bonesis_toy_interactions["paper"]<-bonesis_toy_edges$paper
bonesis_toy_interactions["RF"]<-bonesis_toy_edges$RF

bonesis_toy_paper_interactions<-bonesis_toy_interactions[which(bonesis_toy_interactions$paper=="true"),]
bonesis_toy_RF_interactions<-bonesis_toy_interactions[which(bonesis_toy_interactions$paper=="false"),]
rownames(bonesis_toy_paper_interactions)<-seq(nrow(bonesis_toy_paper_interactions))
rownames(bonesis_toy_RF_interactions)<-seq(nrow(bonesis_toy_RF_interactions))

#Import nodes
bonesis_toy_nodes<-read.csv(paste0(analysis_directory,"/cytoscape/Output/new_bonesis_toy+scenic_nodes.csv"),header=T)[,c(1,2,3)]

#Assign the importance
bonesis_toy_paper_interactions["Importance"]<-bolouri_paper_interactions[find_same_interactions_dfs(bolouri_paper_interactions,bonesis_toy_paper_interactions),]$Interaction

for (x in seq_along(bonesis_toy_paper_interactions$Importance)){
  if(bonesis_toy_paper_interactions$Importance[x]=="inhibits"){
    bonesis_toy_paper_interactions[x,"Importance"]<-1*(-1)
  }else{bonesis_toy_paper_interactions[x,"Importance"]<-1}
}

bonesis_toy_RF_interactions["Importance"]<-0

bonesis_toy_interactions<-rbind(bonesis_toy_paper_interactions,bonesis_toy_RF_interactions)

bonesis_toy_python_2<-c()
for (x in seq(nrow(bonesis_toy_interactions))){
  bonesis_toy_python_2<-append(bonesis_toy_python_2,paste0("(",bonesis_toy_interactions[x,1],",",bonesis_toy_interactions[x,2],",dict(sign=",bonesis_toy_interactions[x,3],")),"))
}

#Assign importance to RF interactions by conducting a pearson correlation of expression data

for (x in seq(nrow(bonesis_toy_RF_interactions))){
  tf<-input[,which(colnames(input)==bonesis_toy_RF_interactions$TF[x])]
  target<-input[,which(colnames(input)==bonesis_toy_RF_interactions$target[x])]
  bonesis_toy_RF_interactions[x,"Importance"]<-cor(tf,target,method="pearson")
}
for (x in seq(nrow(bonesis_toy_RF_interactions))){
  tf<-input[,which(colnames(input)==bonesis_toy_RF_interactions$TF[x])]
  target<-input[,which(colnames(input)==bonesis_toy_RF_interactions$target[x])]
  bonesis_toy_RF_interactions[x,"spearman"]<-cor(tf,target,method="spearman")
}
for (x in seq(nrow(bonesis_toy_RF_interactions))){
  tf<-input[,which(colnames(input)==bonesis_toy_RF_interactions$TF[x])]
  target<-input[,which(colnames(input)==bonesis_toy_RF_interactions$target[x])]
  bonesis_toy_RF_interactions[x,"kendall"]<-cor(tf,target,method="kendall")
}

#Dotplot based on new_bonesis_toy
bonesis_toy_tfs<-bonesis_toy_nodes$name[2:length(bonesis_toy_nodes$name)]

bonesis_toy_tfs<-gsub("TCF-1","HNF1A",bonesis_toy_tfs)
bonesis_toy_tfs<-gsub("CD3, TCR, CD8, CD28","CD28",bonesis_toy_tfs)
bonesis_toy_tfs<-c(bonesis_toy_tfs,"FCER1G")
bonesis_toy_tfs<-gsub("PD-1","PDCD1",bonesis_toy_tfs)
bonesis_toy_tfs<-gsub("CTLA-4","CTLA4",bonesis_toy_tfs)
bonesis_toy_tfs<-gsub("IL12-R","IL12RB1",bonesis_toy_tfs)
bonesis_toy_tfs<-c(bonesis_toy_tfs,"JUN","FOS")

dot_plot_input<-as.data.frame(t(raw_input))

cell_code<-seq(length(cell_annotations$TYPE))
dot_plot_code<-c()
for(x in seq_along(cell_code)){
  dot_plot_code[x]<-paste0(cell_annotations$TYPE[x],"_",cell_code[x])
}
colnames(dot_plot_input)<-dot_plot_code

dot_plot_seurat <- CreateSeuratObject(counts = dot_plot_input, project = "cell_exh", min.cells = 0, min.features = 10)
dot_plot_seurat<-NormalizeData(dot_plot_seurat, normalization.method = "LogNormalize", scale.factor = 10000)
all.genes <- rownames(dot_plot_seurat)
dot_plot_seurat <- ScaleData(dot_plot_seurat, features = all.genes)

DotPlot(dot_plot_seurat, features =c(bonesis_toy_tfs, "ETV7"),cols = c("blue", "red"), dot.scale = 10) + RotatedAxis()+ ggplot2::scale_colour_gradient2(high = "#ff0000", mid = "#FFFFFF", low = "#0000FF")

#Define cell states
cell_states_dot_plot<-data.frame(matrix(nrow=length(cell_types),ncol=nrow(dot_plot_input)))
rownames(cell_states_dot_plot)<-names(cell_types)
colnames(cell_states_dot_plot)<-rownames(dot_plot_input)
cell_states_dot_plot$BACH2<-c(1,NA,NA)
cell_states_dot_plot$BCL6<-NA
cell_states_dot_plot$CD28<-c(1,0,NA)
cell_states_dot_plot$CTLA4<-c(NA,0,1)
#cell_states_dot_plot$EOMES<-c(0,NA,1)
cell_states_dot_plot$EZH2<-c(NA,NA,1)
cell_states_dot_plot$FCER1G<-NA
cell_states_dot_plot$FOXO1<-c(1,0,NA)
cell_states_dot_plot$HNF1A<-NA
cell_states_dot_plot$ID3<-NA
#cell_states_dot_plot$IL12RB1<-c(NA,NA,1)
cell_states_dot_plot$NFATC1<-c(1,NA,NA)
#cell_states_dot_plot$NFATC2<-c(0,NA,NA)
cell_states_dot_plot$PDCD1<-c(NA,0,1)
cell_states_dot_plot$PRDM1<-c(0,NA,1)
```

```{r}
dot_plot_input<-as.data.frame(t(raw_input))

cell_code<-seq(length(cell_annotations$TYPE))
dot_plot_code<-c()
for(x in seq_along(cell_code)){
  dot_plot_code[x]<-paste0(cell_annotations$TYPE[x],"_",cell_code[x])
}
colnames(dot_plot_input)<-dot_plot_code

dot_plot_seurat <- CreateSeuratObject(counts = dot_plot_input, project = "cell_exh", min.cells = 0, min.features = 10)
dot_plot_seurat<-NormalizeData(dot_plot_seurat, normalization.method = "LogNormalize", scale.factor = 10000)
all.genes <- rownames(dot_plot_seurat)
dot_plot_seurat <- ScaleData(dot_plot_seurat, features = all.genes)

DotPlot(dot_plot_seurat, features =c("EZH2","CD28","CTLA4","IL2-R","NFATC1","PDCD1","BTLA","NFKB1","PRDM1","BACH2","FOXO1","ID3","BCL6","HNF1A","IL12RB1","NFATC2","JUN","FOS","TBX21","ZEB2","STAT1"),cols = c("blue", "red"), dot.scale = 10) + RotatedAxis()+ ggplot2::scale_colour_gradient2(high = "#ff0000", mid = "#FFFFFF", low = "#0000FF")
```

#Alternative way
```{r}
#Look for importance values of RF interations_ encode and p-p database
interactions_sign_encode<-read.delim("/media/ag-cherrmann/ischneider/GRNTcellExh/data/interactions_sign/encode.txt")
colnames(interactions_sign_encode)[1]<-"targets"

bonesis_toy_RF_interactions_list<-split(bonesis_toy_RF_interactions$target,bonesis_toy_RF_interactions$TF)
sub<-bonesis_toy_RF_interactions_list[["EZH2"]]
sub<-sub[-3]
sub<-c(sub,"JUN","FOS")
bonesis_toy_RF_interactions_list[["EZH2"]]<-sub

bonesis_toy_RF_interactions_list_encode<-bonesis_toy_RF_interactions_list[which(names(bonesis_toy_RF_interactions_list) %in% colnames(interactions_sign_encode))]

bonesis_toy_RF_interactions_importance_encode<-bonesis_toy_RF_interactions_list_encode
for (tf in names (bonesis_toy_RF_interactions_list_encode)){
  bonesis_toy_RF_interactions_importance_encode[[tf]]<-interactions_sign_encode[which(interactions_sign$targets %in% bonesis_toy_RF_interactions_list_encode[[tf]]),tf]
}

interactions_sign_pp<-read.delim("/media/ag-cherrmann/ischneider/GRNTcellExh/data/interactions_sign/p-p_pathways.txt")
interactions_sign_pp<-interactions_sign_pp[3:nrow(interactions_sign_pp),]
colnames(interactions_sign_pp)[1]<-"targets"

unique(bonesis_toy_RF_interactions$target) %in% interactions_sign_pp$targets

names(bonesis_toy_RF_interactions_list) %in% colnames(interactions_sign_pp)

bonesis_toy_RF_interactions_importance_pp<-bonesis_toy_RF_interactions_list
for (tf in names (bonesis_toy_RF_interactions_list)){
  bonesis_toy_RF_interactions_importance_pp[[tf]]<-interactions_sign_pp[which(interactions_sign$targets %in% bonesis_toy_RF_interactions_list[[tf]]),tf]
}
```


#Analyzing solutions
```{r}
#Create solutions core
solutions_core<-bonesis_rules_list[[2]]
solutions_core<-solutions_core[which(solutions_core$BACH2=="!EZH2" & solutions_core$BTLA=="NFKB1" & solutions_core$EZH2!=1 & solutions_core$IL2.R=="!ID3"),]

#Look how the solution distributions for other nodes has changed
not_core<-c("CD3..TCR..CD8..CD28", "NFATC1", "TCF.1", "CTLA.4","FOXO1","ID3","PD.1","PRDM1")
solutions_not_core_stats<-vector("list", length(not_core))
names(solutions_not_core_stats)<-not_core

for (y in not_core){
  solutions_not_core_stats[[y]]<-table(solutions_core[,y])/nrow(solutions_core)
}

#Remove fixed solutions from CTLA-4 and PRDM1
solutions_core_curated_1<-solutions_core[which(solutions_core$CTLA.4!=1 & solutions_core$PRDM1!=1),]

#Look how the solution distributions for other nodes has changed
not_filtered<-c("CD3..TCR..CD8..CD28", "NFATC1", "TCF.1", "FOXO1","ID3","PD.1")
solutions_not_filtered_stats<-vector("list", length(not_filtered))
names(solutions_not_filtered_stats)<-not_filtered

for (y in not_filtered){
  solutions_not_filtered_stats[[y]]<-table(solutions_core_curated_1[,y])/nrow(solutions_core_curated_1)
}


#Remove fixed solutions from PD-1
solutions_core_curated_2<-solutions_core_curated_1[which(solutions_core_curated_1$PD.1!=1),]

#Look how the solution distributions for other nodes has changed
not_filtered_2<-c("CD3..TCR..CD8..CD28", "NFATC1", "TCF.1", "FOXO1","ID3")
solutions_not_filtered_stats_2<-vector("list", length(not_filtered_2))
names(solutions_not_filtered_stats_2)<-not_filtered_2

for (y in not_filtered_2){
  solutions_not_filtered_stats_2[[y]]<-table(solutions_core_curated_2[,y])/nrow(solutions_core_curated_2)
}

#Fixate FOXO1 and ID3
solutions_core_curated_3<-solutions_core_curated_2[which(solutions_core_curated_2$FOXO1==1),]

#Look how the solution distributions for other nodes has changed
solutions_not_filtered_stats_3<-vector("list", ncol(solutions_core_curated_3))
names(solutions_not_filtered_stats_3)<-colnames(solutions_core_curated_3)

for (y in colnames(solutions_core_curated_3)){
  solutions_not_filtered_stats_3[[y]]<-table(solutions_core_curated_3[,y])/nrow(solutions_core_curated_3)
}
```

#Analyze Bonesis output rules
```{r}
#Open csv files
bonesis_output_top<-read.csv(paste0(analysis_directory,"/bonesis_output/bonesis_toy_rules_top.csv"),header=T, row.names=1)

bonesis_output_bottom<-read.csv(paste0(analysis_directory,"/bonesis_output/bonesis_toy_rules_bottom.csv"),header=T, row.names=1)
out<-c("EZH2","IL12.R","NFATC1","NFATC1.JUN.FOS.IRF4.BATF","NFATC2","TBET.ZEB2")
bonesis_output_bottom<-bonesis_output_bottom[,which(!colnames(bonesis_output_bottom )%in%out)]

#Get the different solution options for each node
bonesis_output_top_stats<-vector("list",ncol(bonesis_output_top))
names(bonesis_output_top_stats)<-colnames(bonesis_output_top)

for (x in names(bonesis_output_top_stats)){
    bonesis_output_top_stats[[x]]<-sort(table(bonesis_output_top[,x])/nrow(bonesis_output_top),decreasing = T)
}

bonesis_output_bottom_stats<-vector("list",ncol(bonesis_output_bottom))
names(bonesis_output_bottom_stats)<-colnames(bonesis_output_bottom)

for (x in names(bonesis_output_bottom_stats)){
    bonesis_output_bottom_stats[[x]]<-sort(table(bonesis_output_bottom[,x])/nrow(bonesis_output_bottom),decreasing = T)
}

bonesis_output_bottom_stats$TCF.1

bonesis_output_top_stats$NFATC1.JUN.FOS.IRF4.BATF

grep("PRDM1",names(bonesis_output_bottom_stats$BCL6))
grep("TCF-1",names(bonesis_output_bottom_stats$BCL6))

```

#Bonesis_final_3
```{r}
#Open csv files
bonesis_output<-read.csv(paste0(analysis_directory,"/bonesis_output/bonesis_toy_final_3_rules.csv"),header=T, row.names=1)

#Get the different solution options for each node
bonesis_output_stats<-vector("list",ncol(bonesis_output))
names(bonesis_output_stats)<-colnames(bonesis_output)

for (x in names(bonesis_output_stats)){
    bonesis_output_stats[[x]]<-sort(table(bonesis_output[,x])/nrow(bonesis_output),decreasing = T)
}

#First curation
bonesis_output_curated_1<-bonesis_output[which(bonesis_output$NFATC2=="STAT1" & bonesis_output$PD.1!=1 & bonesis_output$STAT1!=1 & bonesis_output$CTLA.4!=1 & bonesis_output$CD3..TCR..CD8..CD28!=1),]

#Get the different solution options for each node
bonesis_output_stats_curated_1<-vector("list",ncol(bonesis_output_curated_1))
names(bonesis_output_stats_curated_1)<-colnames(bonesis_output_curated_1)

for (x in names(bonesis_output_stats_curated_1)){
    bonesis_output_stats_curated_1[[x]]<-sort(table(bonesis_output_curated_1[,x])/nrow(bonesis_output_curated_1),decreasing = T)
}

#Second curation
bonesis_output_curated_2<-bonesis_output_curated_1[which(bonesis_output_curated_1$BTLA!=0 & bonesis_output_curated_1$EZH2!=1 & bonesis_output_curated_1$JUN.FOS!=0 & bonesis_output_curated_1$NFATC1.JUN.FOS.IRF4.BATF!=1 & bonesis_output_curated_1$NFKB1!=0),]
bonesis_output_curated_2<-bonesis_output_curated_2[which(bonesis_output_curated_2$NFATC1.JUN.FOS.IRF4.BATF!=0),]

#Save row numbers for attractor analysis
rows<-as.numeric(rownames(bonesis_output_curated_2))

#Get the different solution options for each node
bonesis_output_stats_curated_2<-vector("list",ncol(bonesis_output_curated_2))
names(bonesis_output_stats_curated_2)<-colnames(bonesis_output_curated_2)

for (x in names(bonesis_output_stats_curated_2)){
    bonesis_output_stats_curated_2[[x]]<-sort(table(bonesis_output_curated_2[,x])/nrow(bonesis_output_curated_2),decreasing = T)
}

#Analyze attractors
bonesis_attractors<-vector("list", nrow(bonesis_output_curated_2))
names(bonesis_attractors)<-as.character(seq(0,nrow(bonesis_output_curated_2)-1))
for(x in seq(0,nrow(bonesis_output_curated_2)-1)){
  bonesis_attractors[[as.character(x)]]<-as.character(read.csv(paste0("/media/ag-cherrmann/ischneider/GRNTcellExh/analysis/bonesis_output/attractors_3/",as.character(x),".csv"),header=T, row.names=1))
}

bonesis_attractors<-as.data.frame(t(as.data.frame(bonesis_attractors)))
colnames(bonesis_attractors)<-c("BTLA","CD3, TCR, CD8, CD28","CTLA-4","EZH2","JUN-FOS","NFATC1","NFATC1:JUN-FOS:IRF4:BATF","NFATC2","NFKB1","PD-1","STAT1")
rownames(bonesis_attractors)<-seq(nrow(bonesis_attractors))

bonesis_attractors_stats<-vector("list",ncol(bonesis_attractors))
names(bonesis_attractors_stats)<-colnames(bonesis_attractors)

for (x in names(bonesis_attractors_stats)){
    bonesis_attractors_stats[[x]]<-sort(table(bonesis_attractors[,x])/nrow(bonesis_attractors),decreasing = T)
}

#Prepare for Boolnet
boolnet_input<-as.data.frame(t(bonesis_output_curated_2))

for (x in seq(ncol(boolnet_input))){
  write.table(boolnet_input[,x], file=paste0("/media/ag-cherrmann/ischneider/GRNTcellExh/analysis/boolnet_input/",as.character(x),".tsv"), quote=FALSE, sep='\t', row.names = T)
}
```

#Boolnet
```{r}
loadNetwork("/media/ag-cherrmann/ischneider/GRNTcellExh/analysis/boolnet_input/1.tsv")
```


