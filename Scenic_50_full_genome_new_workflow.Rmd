---
title: "Output_full_genome_new_workflow"
author: "Ilya"
date: "10/06/2022"
output: html_document
---
  
#Download packages
```{r}
#install.packages("RColorBrewer")

#install.packages("LaplacesDemon")

#install.packages(mousetrap)

#install.packages("https://cran.r-project.org/src/contrib/Archive/randomForest/randomForest_4.6-14.tar.gz", repos=NULL, type="source")

#install.packages("RColorBrewer")

#install.packages("igraph")

#install.packages("dplyr")

#install.packages("openxlsx")

#install.packages("gplots")

#if (!require("BiocManager", quietly = TRUE))
#   install.packages("BiocManager")
#BiocManager::install("GenomicRanges")

#if (!require("BiocManager", quietly = TRUE))
#   install.packages("BiocManager")
#BiocManager::install("TxDb.Hsapiens.UCSC.hg38.knownGene")

#if (!require("BiocManager", quietly = TRUE))
#   install.packages("BiocManager")
#BiocManager::install("Homo.sapiens")

#if (!require("BiocManager", quietly = TRUE))
#   install.packages("BiocManager")
#BiocManager::install("plyranges")

#install.packages("ellipsis")
#if (!require("BiocManager", quietly = TRUE))
#   install.packages("BiocManager")
#BiocManager::install("AUCell")

#if (!require("BiocManager", quietly = TRUE))
#install.packages("BiocManager")
#BiocManager::install("GSEABase")

#if (!require("BiocManager", quietly = TRUE))
#   install.packages("BiocManager")
#BiocManager::install("GEOquery")

#if (!require("BiocManager", quietly = TRUE))
    #install.packages("BiocManager")

#BiocManager::install("ComplexHeatmap")
```

#Load packages
```{r}
update.packages("ellipsis")
#library(dplyr)
update.packages("htmltools")
library(GenomicRanges)
library(GenomicFeatures)
library(TxDb.Hsapiens.UCSC.hg38.knownGene)
library(Homo.sapiens)
library(plyranges)
library(AUCell)
library(GSEABase)
library(GEOquery)
library(openxlsx)
library(stringr)
library(gplots)
library(igraph)
library(RColorBrewer)
library(ComplexHeatmap)
library(randomForest)
library(mousetrap)
library(LaplacesDemon)
library(devtools)
library(RColorBrewer)
``` 

#Direcrories
```{r}
main_directory<-"/media/ag-cherrmann/ischneider/GRNTcellExh/scr"
data_directory<-"/media/ag-cherrmann/ischneider/GRNTcellExh/data"
analysis_directory<-"/media/ag-cherrmann/ischneider/GRNTcellExh/analysis"
```

#Edit the input file for the 50 Scenic runs
```{r eval=FALSE, echo=FALSE}
#Read input table
raw_input<-read.csv("/media/ag-cherrmann/cramirez/tcd8ExscSeq/data/maike2020/nina_thimme_raw_counts.csv",header=T, row.names=1)

#Read cell annotations
setwd(data_directory)
cell_annotations<-read.xlsx("nina_annotations.xlsx")

#Remove RNA genes
raw_input<-t(as.data.frame(raw_input))
raw_input<-raw_input[,17:dim(raw_input)[2]]

#Remove chromosme tags and duplicates
genes<-gsub("\\_.*","",colnames(raw_input))
remove<-which(duplicated(genes))
genes<-genes[-remove] 
raw_input<-raw_input[,-remove]
colnames(raw_input)<-genes
raw_input<-as.data.frame(raw_input)

#Bolouri paper nodes with appropriate nomenclature substitutions
paper_nodes<-c("HNF1A","TNFSF9","TNFRSF9","IL12RB1","IL12RB2","IL21R","FCER1G","CD3","CD8","CD28","PIK3K","EZH2","PRC2","IL2R","RAS","MAPK1","JUN","FOS","BATF","AKT1", "AKT2", "AKT3","FOXO1","EGR2","EGR3","BACH2","ID3","ID2","NFKB1","MTOR","IRF4","TCF3","NFATC2","PPARGC1A","BCL6","PRDM1","NFATC1","CXCR5","TBX21","ZEB2","LAG3","PDCD1","HIF1A","KLRG1","PPARA","CTLA4","HAVCR2","BTLA","NR4A1","CD160","TIGIT","IL15RA","CD244","CD2B4","MYC","RUNX3","EOMES","FAS","FASLG","GZMA","GZMB","PRF1","IFNG")
paper_substitutions<-list("HNF1A","TNFRSF9",c("IL12RB1","IL12RB2"),c("AKT1","AKT2","AKT3"),"TCF3","PRDM1","TBX21","PDCD1","PPARA","TNFSF9","FCER1G","MAPK1","PPARGC1A","IL15RA")
names(paper_substitutions)<-c("TCF1","41BB","IL12R","AKT","E2A","BLIMP1","TBET","PD1","PPAR","CD137L","CD3","MAPK","PGC1A","IL15R")

#Keep only cells with annotations
raw_input<-raw_input[cell_annotations$CELLID,]

#Keep only the genes that meet the filtering criteria
input<-raw_input[,names(which(colSums(raw_input)>2*0.01*nrow(raw_input))==T)]

#Include all paper nodes into the input table
paper_nodes_in_input<-paper_nodes[paper_nodes %in% colnames(input)]
paper_nodes_left_out<-paper_nodes[! paper_nodes %in% colnames(input)]
input<-cbind(input,raw_input[,which(colnames(raw_input) %in% paper_nodes_left_out)])
```

#Export the input table
```{r eval=FALSE, echo=FALSE}
setwd("/media/ag-cherrmann/ischneider/GRNTcellExh/data/SCENIC50/Input")
write.table(input, file='scenic_input_full_genome.tsv', quote=FALSE, sep='\t', row.names = T)
#Code for bash to iterate Scenic 50 times
#bash /media/ag-cherrmann/ischneider/GRNTcellExh/scr/Scenic.txt

#Save the table
setwd(analysis_directory)
write.table(input, file='scenic_input_full_genome.tsv', quote=FALSE, sep='\t', row.names = T)
```

#Open input table
```{r}
input<-read.table(paste0("/media/ag-cherrmann/ischneider/GRNTcellExh/data/SCENIC50/Input","/scenic_input_full_genome.tsv"),sep='\t',header=T)

#Bolouri paper nodes with appropriate nomenclature substitutions
paper_nodes<-c("HNF1A","TNFSF9","TNFRSF9","IL12RB1","IL12RB2","IL21R","FCER1G","CD3","CD8","CD28","PIK3K","EZH2","PRC2","IL2R","RAS","MAPK1","JUN","FOS","BATF","AKT1", "AKT2", "AKT3","FOXO1","EGR2","EGR3","BACH2","ID3","ID2","NFKB1","MTOR","IRF4","TCF3","NFATC2","PPARGC1A","BCL6","PRDM1","NFATC1","CXCR5","TBX21","ZEB2","LAG3","PDCD1","HIF1A","KLRG1","PPARA","CTLA4","HAVCR2","BTLA","NR4A1","CD160","TIGIT","IL15RA","CD244","CD2B4","MYC","RUNX3","EOMES","FAS","FASLG","GZMA","GZMB","PRF1","IFNG")
paper_substitutions<-list("HNF1A","TNFRSF9",c("IL12RB1","IL12RB2"),c("AKT1","AKT2","AKT3"),"TCF3","PRDM1","TBX21","PDCD1","PPARA","TNFSF9","FCER1G","MAPK1","PPARGC1A","IL15RA")
names(paper_substitutions)<-c("TCF1","41BB","IL12R","AKT","E2A","BLIMP1","TBET","PD1","PPAR","CD137L","CD3","MAPK","PGC1A","IL15R")

#Read cell annotations
setwd(data_directory)
cell_annotations<-read.xlsx("nina_annotations.xlsx")
cell_types<-split(cell_annotations,cell_annotations$TYPE)
cell_types<-cell_types[c(2,3,1)]

cell_types_cell_ids<-cell_types
for(x in names(cell_types)){
  cell_types_cell_ids[[x]]<-cell_types[[x]]$CELLID
}
```

#Select all TFs from aucell files
```{r}
#Number of scenic runs
n=50

#Open all aucell files and keep TFs from them
aucell_tfs<-vector("list",length=n)
names(aucell_tfs)<-seq(n)
for (x in seq(n)){
  aucell<-read.csv(paste0(data_directory,"/SCENIC50/Output_full_genome_new_workflow/run_",as.character(x),"/aucell.csv"),header=T,row.names = 1)
  aucell_tfs[[as.character(x)]]<-colnames(aucell)
}

aucell_tfs<-lapply(aucell_tfs, gsub, pattern="[...]",replacement="")
scenic_output_tfs<-unique(unlist(aucell_tfs))
```

#Get targets for TFs from reg files
```{r}
#Get target column from each reg file
reg_targets<-vector("list",length=n)
names(reg_targets)<-seq(n)
for (x in seq(n)){
  reg<-read.csv(paste0(data_directory,"/SCENIC50/Output_full_genome_new_workflow/run_",as.character(x),"/reg.csv"),header=T)
  reg_targets[[as.character(x)]]<-reg
}

change_reg_format<-function(r){
  names<-c(r[2,1:2],r[1,3:dim(r)[2]])
  y<-setNames(r,names)
  y<-y[-c(1,2),]
}

reg_targets<-lapply(reg_targets,change_reg_format)
for (x in names(reg_targets)){
  reg_targets[[x]]<-split(reg_targets[[x]],reg_targets[[x]]$TF)
}

for (x in names(reg_targets)){
  for (y in names(reg_targets[[x]])){
    reg_targets[[x]][[y]]<-reg_targets[[x]][[y]]$TargetGenes
  }
}

#Extract target names
extract_targets <- function(x){
  targets <- regmatches(x, gregexpr("'[^']*'", x))[[1]] 
  gsub("'", '', targets)
}

extract_all_unique_targets<-function(obj){
  unique(extract_targets(paste0(c(obj),collapse = "")))
}

for (x in names(reg_targets)){
  for(y in names(reg_targets[[x]])){
    reg_targets[[x]][[y]]<-extract_all_unique_targets(reg_targets[[x]][[y]])
  }
}

regulons<-reg_targets
for (x in names(reg_targets)){
  for(y in names(reg_targets[[x]])){
    reg_targets[[x]][[y]]<-reg_targets[[x]][[y]][reg_targets[[x]][[y]] %in% scenic_output_tfs] #we keep not only TF->TF interactions
  }
}

#Remove self regulation
for (y in names(reg_targets)){
  for (x in scenic_output_tfs){
    lookup<-x==reg_targets[[y]][[x]]
    pos<-which(lookup==T)
    if(sum(lookup)!=0){
      reg_targets[[y]][[x]]<-reg_targets[[y]][[x]][-c(pos)]
    }
  }
} 

#Remove TFs with no targets
for (x in names(reg_targets)){
  remove<-which(lapply(reg_targets[[x]], length)==0)
  reg_targets[[x]]<-reg_targets[[x]][-remove]
}

reg_tfs<-c()
for (x in names(reg_targets)){
  reg_tfs<-append(reg_tfs,names(reg_targets[[x]]))
}
reg_tfs<-unique(reg_tfs)
```

#Create a file with all the interactions that we want to keep
```{r}
#Put all interactions in dataframe form
all_interactions<-c()
for (z in names(reg_targets)){
  for(x in names(reg_targets[[z]])){
    for(y in reg_targets[[z]][[x]]){
      all_interactions<-append(all_interactions,paste0(x,"->",y))
    }
  }
}

frequency<-(table(all_interactions))
all_unique_interactions<-names(frequency)
interactions_summary<-as.data.frame(matrix(ncol=3,nrow=length(unlist(all_unique_interactions))))
colnames(interactions_summary)<-c("TF", "target","frequency")
interactions_summary$frequency<-as.numeric(frequency)
interactions_summary$TF<-sub("->.*", "", all_unique_interactions)
interactions_summary$target<-sub(".*->", "", all_unique_interactions)

#Add frequency filter
frequency_filter=40
for(x in seq(dim(interactions_summary)[1])){
  f<-interactions_summary$frequency[x]
  if(f>=frequency_filter){
    interactions_summary[x,"frequency_filter"]<-T
  }else{
    interactions_summary[x,"frequency_filter"]<-F
  }
}

#Dataframe for interactions that pass frequency filter
frequency_summary<-interactions_summary[which(interactions_summary$frequency_filter==T),]
frequency_summary_nodes<-unique(c(unique(frequency_summary$target),unique(frequency_summary$TF)))
```

#Caculate NIS score for frequency_summary interactions
```{r echo=FALSE, eval=FALSE}
#Open adj files
adj_files<-vector("list",length=n)
names(adj_files)<-seq(n)
for (x in seq(n)){
  adj<-read.table(paste0(data_directory,"/SCENIC50/Output_full_genome_new_workflow/run_",as.character(x),"/adj.tsv"),sep='\t',header=T)
  adj_files[[as.character(x)]]<-adj
}

#Filter for interactions that are present in frequency_summary
adj_frequency_files<-adj_files
for(y in names(adj_files)){
  keep<-c()
  for (x in seq(nrow(frequency_summary))){
    tf_rows<-which(adj_files[[y]]$TF==frequency_summary[x,]$TF)
    target_rows<-which(adj_files[[y]]$target==frequency_summary[x,]$target)
      if(length(tf_rows)!=0 & length(target_rows)!=0){
       pos<-which(tf_rows %in% target_rows)
        if(length(pos)!=0){
           keep<-append(keep,tf_rows[pos])
        }
      }
  }
  adj_frequency_files[[y]]<-adj_files[[y]][keep,]
}

#Average the importance scores
adj_frequency_files_importance_scores<-vector("list", nrow(frequency_summary))
names(adj_frequency_files_importance_scores)<-seq(nrow(frequency_summary))
for (x in seq(nrow(frequency_summary))){
  imp<-c()
  for(y in names(adj_frequency_files)){
    tf_rows<-which(adj_frequency_files[[y]]$TF==frequency_summary[x,]$TF)
    target_rows<-which(adj_frequency_files[[y]]$target==frequency_summary[x,]$target)
      if(length(tf_rows)!=0 & length(target_rows)!=0){
      pos<-which(tf_rows %in% target_rows)
        if(length(pos)!=0){
          imp<-append(imp,adj_frequency_files[[y]][tf_rows[pos],]$importance)
        }
      }
  }
  adj_frequency_files_importance_scores[[x]]<-mean(imp)
}

#Add IS to the frequency_summary
frequency_summary["IS"]<-unlist(adj_frequency_files_importance_scores)*frequency_summary$frequency

#Split frequency_summary by targets
frequency_summary_targets<-split(frequency_summary,frequency_summary$target)

#Calculate NIS
all_nis<-c()
for (x in names(frequency_summary_targets)){
  nis<-c()
  for (y in seq(nrow(frequency_summary_targets[[x]]))){
    score<-frequency_summary_targets[[x]]$IS[y]/sum(frequency_summary_targets[[x]]$IS)
    nis<-append(nis,score)
  }
  all_nis<-append(all_nis,nis)
}

frequency_summary["NIS"]<-all_nis

#Save the table
write.csv(frequency_summary,paste0(analysis_directory,"/frequency_summary.csv"), row.names = F)
```

#Select best peaks for cistrome
```{r eval=FALSE, echo=FALSE}
#Work with cistrome description file
setwd(data_directory)
cistrome_description<-read.delim("human_factor_full_QC.txt")
cistrome_blood<-cistrome_description[cistrome_description$Tissue_type=="Blood",]

#File 38912 is empty and gives us an error in the loop so we remove it
cistrome_blood<-cistrome_blood[cistrome_blood$DCid!=38912,]
cistrome_blood_file_names<-cistrome_blood$DCid

#Open corresponding files
cistrome_blood_files<-vector("list", length(cistrome_blood_file_names))
names(cistrome_blood_files)<-cistrome_blood_file_names
for (x in cistrome_blood_file_names){
  cistrome_blood_files[[as.character(x)]]<-as.data.frame(read.table(paste0(data_directory,"/human_factor/",as.character(x),"_sort_peaks.narrowPeak.bed"),header = FALSE, sep="\t",stringsAsFactors=FALSE, quote=""))
}

#Keep only TFs that appear in scenic output
names(cistrome_blood_files)<-cistrome_blood$Factor
cistrome_blood_files<-cistrome_blood_files[names(cistrome_blood_files) %in% scenic_output_tfs]

#Split the list into groups according to a TF
cistrome_blood_files<-split(cistrome_blood_files,names(cistrome_blood_files))
cistrome_blood_files<-lapply(cistrome_blood_files, dplyr::bind_rows)

#Select top 10000 peaks for each TF
cistrome_best_peaks<-cistrome_blood_files
for (y in names(cistrome_best_peaks)){
  best_peaks<-unique(head(sort(cistrome_best_peaks[[y]]$V5, decreasing=T),1000))
  keep<-c()
  for (x in best_peaks){
    keep<-append(keep,which(cistrome_best_peaks[[y]]$V5==x))
  }
  cistrome_best_peaks[[y]]<-cistrome_best_peaks[[y]][keep,]
}

#Export cistrome_best_peaks
for (x in names(cistrome_best_peaks)){
  write.csv(cistrome_best_peaks[[x]],paste0(analysis_directory,"/","cistrome_best_peaks/",x,".csv"), row.names = F)
}
```

#Import cistrome_best_peaks
```{r}
best_peaks_file_names<-list.files(paste0(analysis_directory,"/","cistrome_best_peaks"))
cistrome_best_peaks<-list()
for (x in seq_along(best_peaks_file_names)){
  cistrome_best_peaks[[x]]<-read.csv(paste0(analysis_directory,"/","cistrome_best_peaks/",best_peaks_file_names[x]))
}
names(cistrome_best_peaks)<-sub(".csv*.", "", best_peaks_file_names)
```

#Prepare Cistrome peaks for intersection with reference genome
```{r}
#Change peak format
change_peak_format<-function(peak){
  y<-peak[,c(1,2,3,6)]
  new_names<-c("chr","start","end","strand")
  setNames(y,new_names)
}
cistrome_best_peaks<-lapply(cistrome_best_peaks,change_peak_format)

#Extend the peaks by 10 kb in both directions
extension=10000
extend_peaks<-function(peak, e){
  peak<-mutate(peak,start=start-e)
  peak<-mutate(peak,end=end+e)
}
cistrome_extended_peaks<-lapply(cistrome_best_peaks,extend_peaks,e=extension)
for(y in names(cistrome_extended_peaks)){
  for (x in seq_along(cistrome_extended_peaks[[y]]$start)){
    if(cistrome_extended_peaks[[y]]$start[x]<0){
      cistrome_extended_peaks[[y]][x,2]<-0
    }
  }
}
cistrome_granges_peaks<-cistrome_extended_peaks

#Make Granges objects
for (x in names(cistrome_extended_peaks)){
  cistrome_granges_peaks[[x]]<-makeGRangesFromDataFrame(cistrome_extended_peaks[[x]])
}
```

#Overlap peaks with reference genome
```{r}
#Get reference transcripts
txdb <- TxDb.Hsapiens.UCSC.hg38.knownGene
transcripts <- GenomicFeatures::genes(txdb)

#Get reference genes
TxDb(Homo.sapiens) <- txdb
genes_list <- transcriptsBy(Homo.sapiens, columns = "SYMBOL")
genes <- unlist(genes_list)
cistrome_overlap_transcripts<-lapply(cistrome_granges_peaks, GenomicRanges::intersect, y=transcripts, ignore.strand=T)

#Create overlap and obtain gene names
cistrome_overlap_genes<-lapply(cistrome_overlap_transcripts,plyranges::find_overlaps,y=genes)
cistrome_overlap_gene_names<-lapply(cistrome_overlap_genes,function(x){unique(unlist(x$SYMBOL))})
total_genes<-unique(unlist(cistrome_overlap_gene_names))
scenic_cistrome_overlap<-scenic_output_tfs[scenic_output_tfs %in% total_genes]
paper_nodes[paper_nodes %in% scenic_cistrome_overlap]
cistrome_overlap_gene_names<-lapply(cistrome_overlap_gene_names, function(x){x[x %in% scenic_output_tfs]})

#Add cistrome filter to interactions_summary
cistrome_confirmed_interactions<-c()
for (z in names(cistrome_overlap_gene_names)){
  for(y in cistrome_overlap_gene_names[[z]]){
    cistrome_confirmed_interactions<-append(cistrome_confirmed_interactions,paste0(z,"->",y))
  }
}
our_cistrome_confirmed_interactions<-cistrome_confirmed_interactions[cistrome_confirmed_interactions %in% all_unique_interactions]
interactions_summary["cistrome_filter"]<-F
interactions_summary[which(all_unique_interactions %in% our_cistrome_confirmed_interactions),"cistrome_filter"]<-T

#Dataframe for interactions that pass cistrome filter
cistrome_summary<-interactions_summary[which(interactions_summary$cistrome_filter==T),]
cistrome_summary_nodes<-unique(c(unique(cistrome_summary$TF),unique(cistrome_summary$target)))

#Dataframe for interactions that pass frequency and cistrome filter
frequency_cistrome_summary<-interactions_summary[which(interactions_summary$cistrome_filter==T &interactions_summary$frequency_filter==T),]
frequency_cistrome_summary_nodes<-unique(c(unique(frequency_cistrome_summary$target),unique(frequency_cistrome_summary$TF)))
```

#Plot interactions from frequency filter marking the ones confirmed by cistrome
```{r}
#Select dataframe for plotting and plot it
frequency_interactions_plot<-interactions_summary[which(interactions_summary$frequency_filter==T),]
frequency_interactions_plot<-frequency_interactions_plot[,c(1,2,5)]
vertices.df <- data.frame(genes=unique(c(frequency_interactions_plot$target, frequency_interactions_plot$TF)),cistrome=0)
vertices.df["cistrome"]<-as.numeric(vertices.df$genes %in% frequency_cistrome_summary_nodes)

## Importing to igraph
g <- graph_from_data_frame(d = frequency_interactions_plot, directed = TRUE, vertices = vertices.df)
V(g)$degree <- degree(g)
#colrs <- c("gray50", "tomato")
#V(g)$color <- colrs[V(g)$cistrome]

## Select vertices with highest degrees
v.degree <- degree(g)
v.sorted <- sort(v.degree, decreasing = TRUE)
v.sorted<-names(which(v.sorted>5))

g.subset <- induced_subgraph(g, v = v.sorted)
l <- layout_with_fr(g.subset)

plot(g.subset, 
     layout=l,
     edge.arrow.size=0.1,
     vertex.size=(V(g.subset)$degree/max(V(g.subset)$degree)*15),
     vertex.label.cex=(V(g.subset)$degree/max(V(g.subset)$degree)*1.3),
     edge.width=0.5,
     vertex.frame.color='white')

pdf(paste0(analysis_directory,'/figures/frequency_interactions_plot.pdf'),
     width=15,
     height=12)
plot(g.subset, 
     layout=l,
     edge.arrow.size=0.1,
     vertex.size=(V(g.subset)$degree/max(V(g.subset)$degree)*18),
     vertex.label.cex=(V(g.subset)$degree/max(V(g.subset)$degree)*1.5),
     edge.width=0.5,
     vertex.frame.color='white')
dev.off()
``` 

#ATAC-seq data
```{r}
#Selecet only targets and TFs from atac_seq file
atac_seq<-read.table(paste0(data_directory,"/CHaRs_annotated.tsv"),sep='\t',header=T)
keep<-c()
for (x in seq(dim(atac_seq)[1])){
  if(atac_seq$genes[x]!=""){
    keep<-append(keep,x)
  }
}
atac_seq<-atac_seq[keep,]
atac_seq_list<-vector("list", dim(atac_seq)[1])
names(atac_seq_list)<-atac_seq$genes
for (x in seq(length(atac_seq_list))){
  
  str<-atac_seq$TF[[x]]
  
  one<-sub(";.*", "", str)
  two<-str_match_all(str, ";\\s*(.*?)\\s*;")[[1]][,2]
  three<-sub(".*;", "", str)
  
  res<-c(one, two, three)
  
  atac_seq_list[[x]]<-res
  
}
atac_seq_list<-split(atac_seq_list,names(atac_seq_list))
atac_seq_list<-lapply(atac_seq_list,unlist)
atac_seq_list<-lapply(atac_seq_list, unique)

#Deal with complex target names
multiple_targets<-atac_seq_list[grep(";", names(atac_seq_list))]
converted_targets<-list()
for (x in names(multiple_targets)){
  one<-sub(";.*", "", x)
  two<-str_match_all(x, ";\\s*(.*?)\\s*;")[[1]][,2]
  three<-sub(".*;", "", x)
  
  res<-c(one, two, three)
  
  for (y in res){
    converted_targets[[y]]<-multiple_targets[[x]]
  }
}
atac_seq_list<-atac_seq_list[-which(names(atac_seq_list) %in% names(multiple_targets))]
atac_seq_list<-c(converted_targets,atac_seq_list)
atac_seq_list<-split(atac_seq_list,names(atac_seq_list))
atac_seq_list<-lapply(atac_seq_list,unlist)
atac_seq_list<-lapply(atac_seq_list, unique)

#Keep only TF->TF interactions
atac_seq_list<-atac_seq_list[which(names(atac_seq_list) %in% scenic_output_tfs)]
for (x in names(atac_seq_list)){
  atac_seq_list[[x]]<-atac_seq_list[[x]][atac_seq_list[[x]] %in% scenic_output_tfs]
}

#Create ATAC-seq interactions
atac_seq_interactions<-c()
for (x in names(atac_seq_list)){
  for(y in atac_seq_list[[x]]){
    atac_seq_interactions<-append(atac_seq_interactions,paste0(y,"->",x))
  }
}

#Add interactions to the interactions_summary table 
interactions_summary["ataq-seq"]<-F
interactions_summary[which(all_unique_interactions %in% atac_seq_interactions),"ataq-seq"]<-T
interactions_summary[interactions_summary$`ataq-seq`==T,]

#Dataframe for interactions that pass ataq_seq filter
ataq_seq_summary<-interactions_summary[which(interactions_summary$`ataq-seq`==T),]

#Dataframe for interactions that pass frequency and ataq_seq filter
frequency_ataq_seq_summary<-interactions_summary[which(interactions_summary$`ataq-seq`==T & interactions_summary$frequency_filter==T),]
frequency_ataq_seq_summary_nodes<-unique(c(unique(frequency_ataq_seq_summary$TF),unique(frequency_ataq_seq_summary$target)))
```

#Select regulons for binarizing their aucell scores
```{r}
#Filter regulons list for TFs that pass frequency filter
frequency_regulons<-vector("list", length(regulons))
names(frequency_regulons)<-names(regulons)
for (x in names(regulons)){
  keep<-names(regulons[[x]])[names(regulons[[x]])%in% frequency_summary_nodes]
  frequency_regulons[[x]]<-regulons[[x]][keep]
}

#Remove the scenic runs list levels and unite all the targets of each TF as one entry
regulon_targets<-vector("list", length(frequency_summary_nodes))
names(regulon_targets)<-frequency_summary_nodes
for (y in frequency_summary_nodes){
  a<-list()
  for (x in names(frequency_regulons)){
    if (sum(y==names(frequency_regulons[[x]]))!=0){
    pos<-which(names(frequency_regulons[[x]])==y)
    a[[x]]<-frequency_regulons[[x]][[pos]]
    }
  }
  regulon_targets[[y]]<-a
}
```

#Conduct new aucell for the selected regulons
```{r}
#Keep only unique interactions that satisfy our frequency criteria
for (x in names(regulon_targets)){
  regulon_targets[[x]]<-sort(table(unlist(regulon_targets[[x]])),decreasing = T)
}

for (x in names(regulon_targets)){
  regulon_targets[[x]]<-names(which((regulon_targets[[x]]>=1)==T))
}

#Remove small regulons: < 15 interactions
remove<-which(lapply(regulon_targets, length)<15)
remove_names<-names(remove)
regulon_targets<-regulon_targets[-remove]

#Select only the cells that have a cell type assigned to it
input_for_single_aucell<-t(input)
input_for_single_aucell<-input_for_single_aucell[,cell_annotations$CELLID]

#Run AUCell
expr_matrix <- as(input_for_single_aucell, "dgCMatrix")
cells_rankings<-AUCell_buildRankings(expr_matrix)

cells_AUC <- AUCell_calcAUC(regulon_targets, cells_rankings)
cells_assignment <- AUCell_exploreThresholds(cells_AUC, plotHist=TRUE, assign=TRUE)
```

#Make a heatmap to represent the aucell scores
```{r}
#Get AUCell matrix
aucell_scores<-as.data.frame(getAUC(cells_AUC))

#Get cell ids grouped accroding to phenotype in the AUCell matrix
cell_ids_ordered<-c()
for (x in names(cell_types)){
  cell_ids_ordered<-append(cell_ids_ordered,cell_types[[x]]$CELLID)
}

aucell_scores<-aucell_scores[,cell_ids_ordered]
aucell_scores<-aucell_scores[sort(rownames(aucell_scores)),]

#Make a heatmap
#heatmap(as.matrix(aucell_scores),Colv = NA, Rowv = NA, scale="none",col = bluered(100))

pdf(paste0(analysis_directory,'/figures/new_aucell_not_norm.pdf'),
     width=15,
     height=40)

Heatmap(aucell_scores,cluster_rows = F,cluster_columns = F, column_labels = rep("",length(colnames(aucell_scores))), column_split = rep(names(cell_types), times = c(dim(cell_types[[1]])[1],dim(cell_types[[2]])[1],dim(cell_types[[3]])[1])))
dev.off()

aucell_scores_norm<-t(scale(t(aucell_scores)))

pdf(paste0(analysis_directory,'/figures/new_aucell_norm.pdf'),
     width=15,
     height=40)

Heatmap(aucell_scores_norm,cluster_rows = F,cluster_columns = F, column_labels = rep("",length(colnames(aucell_scores))), column_split = rep(names(cell_types), times = c(dim(cell_types[[1]])[1],dim(cell_types[[2]])[1],dim(cell_types[[3]])[1])))
dev.off()

#Test distributions of aucell scores for bimodality
sum(apply(aucell_scores, 1, is.bimodal))/dim(aucell_scores)[1]
sum(apply(aucell_scores, 1, bimodality_coefficient)>0.555)/dim(aucell_scores)[1]

#Distributions of aucell scores within each cell_type
aucell_scores_norm_cell_types<-cell_types_cell_ids
for (x in names(cell_types_cell_ids)){
  aucell_scores_norm_cell_types[[x]]<-aucell_scores_norm[,cell_types_cell_ids[[x]]]
}

aucell_scores_norm_cell_types<-lapply(aucell_scores_norm_cell_types, rowMeans)

for (x in aucell_scores_norm_cell_types){
  hist(x, breaks=50)
}
```

#Random Forest to identify TFs that explain the most cell phenotypes
```{r eval=FALSE, echo=FALSE}
#Create dataframe for the random forest
random_forest_input<-rbind(rep(names(cell_types), times = c(dim(cell_types[[1]])[1],dim(cell_types[[2]])[1],dim(cell_types[[3]])[1])),aucell_scores)
rownames(random_forest_input)[1]<-"cell_type"
random_forest_input<-as.data.frame(t(random_forest_input))

#Create a Random Forest model with default parameters
aucell_model <- randomForest(as.factor(cell_type) ~ ., data = random_forest_input, importance = TRUE)
aucell_model_importance<-as.data.frame(importance(aucell_model))
aucell_model_importance<-aucell_model_importance[order(aucell_model_importance$MeanDecreaseAccuracy, decreasing = T),]

#See which Tfs we keep for further interactions
varImpPlot(aucell_model) #Top 30 ones are represented at htis graph so we keep them
aucell_model_importance_top30<-head(rownames(aucell_model_importance),30)
aucell_model_importance_top100<-head(rownames(aucell_model_importance),100)

#Save the tables
write.csv(aucell_model_importance_top30 ,paste0(analysis_directory,"/aucell_model_importance_top30.csv"), row.names = F)
write.csv(aucell_model_importance_top100 ,paste0(analysis_directory,"/aucell_model_importance_top100.csv"), row.names = F)
```

#Scores binarising for 100 TFs from random forest
```{r}
aucell_model_importance_top100<-read.csv(paste0(analysis_directory,"/aucell_model_importance_top100.csv"))[,1]

#Heatmap of averages for each phenotype
aucell_scores_norm_cell_types<-cell_types_cell_ids
for (x in names(cell_types_cell_ids)){
  aucell_scores_norm_cell_types[[x]]<-aucell_scores_norm[aucell_model_importance_top100,][,cell_types_cell_ids[[x]]]
}

aucell_scores_norm_cell_types_means<-lapply(aucell_scores_norm_cell_types, rowMeans)
aucell_scores_norm_cell_types_means<-as.data.frame(aucell_scores_norm_cell_types_means)

pdf(paste0(analysis_directory,'/figures/aucell_scores_norm_top100_cell_type_average.pdf'),
     width=15,
     height=30)

Heatmap(aucell_scores_norm_cell_types_means,cluster_rows = F,cluster_columns = F, column_labels = names(cell_types))
dev.off()

#Cell type specific distribution (averages of each TF in a cell type)
for (x in names(aucell_scores_norm_cell_types_means)){
  hist(aucell_scores_norm_cell_types_means[[x]], breaks=30, main=x)
}

lapply(aucell_scores_norm_cell_types_means, is.bimodal)
lapply(aucell_scores_norm_cell_types_means, bimodality_coefficient)>0.555

#Use k means to separate each cell type into two groups
aucell_scores_norm_cell_types_means_kmeans<-apply(aucell_scores_norm_cell_types_means,2,kmeans,centers=2, nstart=100)

for (x in names(aucell_scores_norm_cell_types_means_kmeans)){
  aucell_scores_norm_cell_types_means_kmeans[[x]]<-aucell_scores_norm_cell_types_means_kmeans[[x]]$cluster
}

#See what clusters belong to active type
for (x in names(aucell_scores_norm_cell_types_means_kmeans)){
  aucell_scores_norm_cell_types_means_kmeans[[x]]<-split(aucell_scores_norm_cell_types_means_kmeans[[x]],aucell_scores_norm_cell_types_means_kmeans[[x]])
}

min_max<-aucell_scores_norm_cell_types_means_kmeans
for (x in names(aucell_scores_norm_cell_types_means_kmeans)){
  for (y in names(aucell_scores_norm_cell_types_means_kmeans[[x]])){
    h<-aucell_scores_norm_cell_types_means[names(aucell_scores_norm_cell_types_means_kmeans[[x]][[y]]),x]
    hist(h, breaks=30, main=paste0(x,"_",y))
    min_max[[x]][[y]]<-c(min(h),max(h))
  }
}

#Binarize dataframe with cell type averages
aucell_scores_norm_cell_types_means_binarized<-data.frame(matrix(ncol=length(aucell_scores_norm_cell_types_means_kmeans),nrow=nrow(aucell_scores_norm_cell_types_means)))
colnames(aucell_scores_norm_cell_types_means_binarized)=names(aucell_scores_norm_cell_types_means_kmeans)
rownames(aucell_scores_norm_cell_types_means_binarized)=rownames(aucell_scores_norm_cell_types_means)

for (x in names(aucell_scores_norm_cell_types_means_kmeans)[1:2]){
  aucell_scores_norm_cell_types_means_binarized[names(aucell_scores_norm_cell_types_means_kmeans[[x]][[1]]),x]<-1
  aucell_scores_norm_cell_types_means_binarized[names(aucell_scores_norm_cell_types_means_kmeans[[x]][[2]]),x]<-0
}

aucell_scores_norm_cell_types_means_binarized[names(aucell_scores_norm_cell_types_means_kmeans[["exh"]][[2]]),"exh"]<-1
aucell_scores_norm_cell_types_means_binarized[names(aucell_scores_norm_cell_types_means_kmeans[["exh"]][[1]]),"exh"]<-0

Heatmap(as.data.frame(aucell_scores_norm_cell_types_means_binarized),cluster_rows = F,cluster_columns = F, column_labels = names(cell_types))

pdf(paste0(analysis_directory,'/figures/aucell_scores_norm_top100_cell_type_average_binarized.pdf'),
     width=15,
     height=30)

Heatmap(aucell_scores_norm_cell_types_means_binarized,cluster_rows = F,cluster_columns = F, column_labels = names(cell_types))
dev.off()

#Define a threshold to binarize all the cells
cutoff_thresholds<-c()
for (x in names(min_max)){
  to_avg<-c(min_max[[x]][[1]][1],min_max[[x]][[2]][2])
  avg<-mean(to_avg)
  cutoff_thresholds<-append(cutoff_thresholds,avg)
}
names(cutoff_thresholds)<-names(min_max)

#Binarize dataframe with all the cells
aucell_scores_norm_cell_types_binarized<-aucell_scores_norm_cell_types
for (z in names(aucell_scores_norm_cell_types_binarized)){
  t_f<-aucell_scores_norm_cell_types[[z]]>cutoff_thresholds[z]
  for (x in seq(ncol(aucell_scores_norm_cell_types[[z]]))){
    pos<-which(t_f[,x]==T)
    aucell_scores_norm_cell_types_binarized[[z]][pos,x]<-1
    aucell_scores_norm_cell_types_binarized[[z]][-pos,x]<-0
  }
}

aucell_scores_norm_cell_types_binarized<-lapply(aucell_scores_norm_cell_types_binarized,function(x){rowSums(x)/ncol(x)})
aucell_scores_norm_cell_types_binarized<-as.data.frame(aucell_scores_norm_cell_types_binarized)

Heatmap(aucell_scores_norm_cell_types_binarized,cluster_rows = F,cluster_columns = F, column_labels = names(cell_types))

pdf(paste0(analysis_directory,'/figures/aucell_scores_norm_top100_cell_type_binarized_percentage.pdf'),
     width=15,
     height=30)

Heatmap(aucell_scores_norm_cell_types_binarized,cluster_rows = F,cluster_columns = F, column_labels = names(cell_types))
dev.off()
```

#Assign cell type to each TF
```{r}
#Find max expression in each TF
aucell_scores_norm_cell_types_binarized_max<-apply(aucell_scores_norm_cell_types_binarized,1,max)
aucell_scores_norm_cell_types_binarized_max_cell_type<-aucell_scores_norm_cell_types_binarized_max
for (x in names(aucell_scores_norm_cell_types_binarized_max)){
  aucell_scores_norm_cell_types_binarized_max_cell_type[x]<-colnames(aucell_scores_norm_cell_types_binarized)[which(aucell_scores_norm_cell_types_binarized[x,]==aucell_scores_norm_cell_types_binarized_max[x])]
}

#Order them alphabetically
aucell_scores_norm_cell_types_binarized_max_cell_type<-aucell_scores_norm_cell_types_binarized_max_cell_type[order(names(aucell_scores_norm_cell_types_binarized_max_cell_type))]

#Overview
table(aucell_scores_norm_cell_types_binarized_max_cell_type)

#Make a list for each cell type
acuell_scores_max_expr_assignment<-split(names(aucell_scores_norm_cell_types_binarized_max_cell_type),aucell_scores_norm_cell_types_binarized_max_cell_type)
```

#Hierarchical clustering of binarized scores to compare our cell type/TF assignment
```{r}
#Cluster
dd <- dist(aucell_scores_norm_cell_types_binarized, method = "euclidean")
hc <- hclust(dd, method = "ward.D2")

#Split into 3 groups
acuell_scores_hclust_3g_assignment<-split(names(cutree(hc, k = 3))[order(names(cutree(hc, k = 3)))],cutree(hc, k = 3))

#Compare the assignments
max_expr_hclust_3g_overlap<-vector("list",length(acuell_scores_hclust_3g_assignment))
names(max_expr_hclust_3g_overlap)<-names(acuell_scores_hclust_3g_assignment)
for (x in names(acuell_scores_hclust_3g_assignment)){
  best_match<-c()
  for (y in names(acuell_scores_max_expr_assignment)){
    match<-1-length(setdiff(acuell_scores_hclust_3g_assignment[[x]],acuell_scores_max_expr_assignment[[y]]))/length(acuell_scores_hclust_3g_assignment[[x]])
    best_match<-append(best_match, match)
  }
  max_expr_hclust_3g_overlap[[x]]<-best_match
}

#Split into 2 groups
acuell_scores_hclust_2g_assignment<-split(names(cutree(hc, k = 2))[order(names(cutree(hc, k = 2)))],cutree(hc, k = 2))
max_expr_hclust_2g_overlap<-vector("list",length(acuell_scores_hclust_2g_assignment))
names(max_expr_hclust_2g_overlap)<-names(acuell_scores_hclust_2g_assignment)
for (x in names(acuell_scores_hclust_2g_assignment)){
  best_match<-c()
  for (y in names(acuell_scores_max_expr_assignment)){
    match<-1-length(setdiff(acuell_scores_hclust_2g_assignment[[x]],acuell_scores_max_expr_assignment[[y]]))/length(acuell_scores_hclust_2g_assignment[[x]])
    best_match<-append(best_match, match)
  }
  max_expr_hclust_2g_overlap[[x]]<-best_match
}
```

#Create a network and communities using 90% as scenic filter and 100 TFs from RF
```{r}
#Import frequency_summary
frequency_summary<-read.csv(paste0(analysis_directory,"/frequency_summary.csv"),header=T)

#Select only interactions that are among top 100 TFs
frequency_summary_top100<-frequency_summary[which(frequency_summary$TF %in% aucell_model_importance_top100),]
frequency_summary_top100<-frequency_summary_top100[which(frequency_summary_top100$target %in% aucell_model_importance_top100),]
frequency_summary_top100<-frequency_summary_top100[which(frequency_summary_top100$frequency>=45),]
frequency_summary_top100<-frequency_summary_top100[,c(1,2,6)]

vertices.df<-data.frame(unique(c(frequency_summary_top100$TF,frequency_summary_top100$target))[order(unique(c(frequency_summary_top100$TF,frequency_summary_top100$target)))])
vertices.df["most_expressed_in"]<-aucell_scores_norm_cell_types_binarized_max_cell_type[names(aucell_scores_norm_cell_types_binarized_max_cell_type) %in% vertices.df[,1]]

#Look how many of these interactions are confirmed by cistrome and frequency
frequency_cistrome_summary_top100<-frequency_cistrome_summary[which(frequency_cistrome_summary$TF %in% aucell_model_importance_top100),]
frequency_cistrome_summary_top100<-frequency_cistrome_summary_top100[which(frequency_cistrome_summary_top100$target %in% aucell_model_importance_top100),]
frequency_cistrome_summary_top100<-frequency_cistrome_summary_top100[which(frequency_cistrome_summary_top100$frequency>=45),]

#Add cistrome column to the frequency_summary_top100 dataframe
frequency_summary_top100["cistrome_filter"]<-F
for (x in seq(nrow(frequency_cistrome_summary_top100))){
  tf_row<-which(frequency_summary_top100$TF==frequency_cistrome_summary_top100[x,]$TF)
  target_row<-which(frequency_summary_top100$target==frequency_cistrome_summary_top100[x,]$target)
  pos<-tf_row[which(tf_row %in% target_row)]
  frequency_summary_top100[pos,"cistrome_filter"]<-T
}

#Look how many of our nodes overlap with the paper
paper_top100_overlap<-paper_nodes[paper_nodes %in% unique(c(frequency_summary_top100$TF,frequency_summary_top100$target))]

# Importing to igraph
g <- graph_from_data_frame(d = frequency_summary_top100, directed = TRUE, vertices = vertices.df)
V(g)$degree <- degree(g)

# Select vertices with highest degrees
v.degree <- degree(g)
v.sorted <- sort(v.degree, decreasing = TRUE)
v.sorted<-names(v.sorted)

#Color nodes according to their highest expression
colrs <- c("#FB8072","#80B1D3","#BEBADA")
my_color<-colrs[as.numeric(as.factor(V(g)$most_expressed_in))]

#Add weight to edges
E(g)$weight<-frequency_summary_top100$NIS

g <- induced_subgraph(g, v = v.sorted)
l <- layout_with_fr(g)

pdf(paste0(analysis_directory,'/figures/frequency_90_interactions_top100_plot.pdf'),
     width=15,
     height=15)
plot(g, 
     layout=l,
     edge.arrow.size=0.25,
     edge.color=c("grey","dark red")[as.numeric(as.factor(E(g)$cistrome_filter))],
     vertex.size=5,
     vertex.label.cex=0.4,
     vertex.color=my_color,
     edge.width=E(g)$weight*3,
     vertex.frame.color='white')
legend(x=-1, y=-0.5, c("Exhausted","Memory", "Transition"), pch=21,
       col="#777777", pt.bg=colrs, pt.cex=2, cex=1.5, bty="n", ncol=1)
dev.off()

#Louvain_clustering
louvain_clustering_res_0.5<-cluster_louvain(as.undirected(g),weight=frequency_summary_top100$NIS, resolution = 0.5)

#Get the communities
louvain_clustering_res_0.5_communities<-louvain_clustering_res_0.5$membership
names(louvain_clustering_res_0.5_communities)<-louvain_clustering_res_0.5$names
louvain_clustering_res_0.5_communities<-split(names(louvain_clustering_res_0.5_communities),louvain_clustering_res_0.5_communities)

#Plot the communities
pdf(paste0(analysis_directory,'/figures/frequency_90_interactions_top100_communities_plot.pdf'),
     width=15,
     height=15)
plot(louvain_clustering_res_0.5,g, 
     layout=l,
     edge.arrow.size=0.25,
     edge.color=c("grey","dark red")[as.numeric(as.factor(E(g)$cistrome_filter))],
     vertex.size=5,
     vertex.label.cex=0.4,
     vertex.color=my_color,
     edge.width=E(g)$weight*3,
     vertex.frame.color='white')
legend(x=-1, y=-0.5, c("Exhausted","Memory", "Transition"), pch=21,
       col="#777777", pt.bg=colrs, pt.cex=2, cex=1.5, bty="n", ncol=1)
dev.off()

#Plot each community
for (x in names(louvain_clustering_res_0.5_communities)){
   
  frequency_summary_com<-frequency_summary[which(frequency_summary$TF %in% louvain_clustering_res_0.5_communities[[x]]),]
  frequency_summary_com<-frequency_summary_com[which(frequency_summary_com$target %in% louvain_clustering_res_0.5_communities[[x]]),]
  frequency_summary_com<-frequency_summary_com[which(frequency_summary_com$frequency>=45),]
  frequency_summary_com<-frequency_summary_com[,c(1,2,6)]
  
  vertices.df_com<-data.frame(unique(c(frequency_summary_com$TF,frequency_summary_com$target))[order(unique(c(frequency_summary_com$TF,frequency_summary_com$target)))])
  vertices.df_com["most_expressed_in"]<-aucell_scores_norm_cell_types_binarized_max_cell_type[names(aucell_scores_norm_cell_types_binarized_max_cell_type) %in% vertices.df_com[,1]]
  
  #Add cistrome_filter column
  frequency_summary_com["cistrome_filter"]<-F
  for (y in seq(nrow(frequency_cistrome_summary_top100))){
    tf_row<-which(frequency_summary_com$TF==frequency_cistrome_summary_top100[y,]$TF)
    target_row<-which(frequency_summary_com$target==frequency_cistrome_summary_top100[y,]$target)
    if(length(tf_row)!=0 & length(target_row)!=0){
      pos<-tf_row[which(tf_row %in% target_row)]
      if (length(pos)!=0){
       frequency_summary_com[pos,"cistrome_filter"]<-T 
      }
    }
  }
  
  #Import to igraph
  g <- graph_from_data_frame(d = frequency_summary_com, directed = TRUE, vertices = vertices.df_com)
  V(g)$degree <- degree(g)
  
  # Select vertices with highest degrees
  v.degree <- degree(g)
  v.sorted <- sort(v.degree, decreasing = TRUE)
  v.sorted<-names(v.sorted)
  
  #Color nodes according to their highest expression
  colrs <- c("#FB8072","#80B1D3","#BEBADA")
  my_color<-colrs[as.numeric(as.factor(V(g)$most_expressed_in))]
  
  #Add weight to edges
  E(g)$weight<-frequency_summary_com$NIS
  
  g <- induced_subgraph(g, v = v.sorted)
  l <- layout_with_fr(g)
  
  pdf(paste0(analysis_directory,"/figures/louvain_clustering_res_0.5_communities_90/community_",as.character(x) ,".pdf"),
       width=15,
       height=15)
  plot(g, 
       layout=l,
       edge.arrow.size=0.25,
       edge.color=c("grey","dark red")[as.numeric(as.factor(E(g)$cistrome_filter))],
       vertex.size=5,
       vertex.label.cex=0.4,
       vertex.color=my_color,
       edge.width=E(g)$weight*3,
       vertex.frame.color='white')
  dev.off()
    
}
```

#Create table for cytoscape
```{r echo=FALSE, eval=FALSE}
#Nodes table
cytoscape_nodes<-vertices.df
colnames(cytoscape_nodes)[1]<-"nodes"
cytoscape_nodes["group"]<-0

for (x in names(louvain_clustering_res_0.5_communities)){
  for (y in louvain_clustering_res_0.5_communities[[x]]){
    pos<-which(cytoscape_nodes$nodes==y)
    cytoscape_nodes[pos,"group"]<-x
  }
}

#Interactions table
cytoscape_interactions<-frequency_summary_top100

#Merge both tables
cytoscape<-cytoscape_interactions

#Get information for TFs and targets
cytoscape["TF_most_expressed_in"]<-"none"
cytoscape["TF_group"]<-0
cytoscape["target_most_expressed_in"]<-"none"
cytoscape["target_group"]<-0

for (x in seq(nrow(cytoscape))){
  pos<-which(cytoscape_nodes$nodes==cytoscape$TF[x])
  cytoscape[x,"TF_most_expressed_in"]<-cytoscape_nodes[pos,"most_expressed_in"]
  cytoscape[x,"TF_group"]<-cytoscape_nodes[pos,"group"]
  
  pos2<-which(cytoscape_nodes$nodes==cytoscape$target[x])
  cytoscape[x,"target_most_expressed_in"]<-cytoscape_nodes[pos2,"most_expressed_in"]
  cytoscape[x,"target_group"]<-cytoscape_nodes[pos2,"group"]
}

#Reorder columns
cytoscape<-cytoscape[,c(1,5,6,2,7,8,3,4)]

cytoscape["TF_group"]<-as.integer(cytoscape$TF_group)
cytoscape["target_group"]<-as.integer(cytoscape$target_group)

#Save the table
setwd(analysis_directory)
write.table(cytoscape, file='cytoscape_05.tsv', quote=FALSE, sep='\t', row.names = F)
```

#Keep only nodes and interactions from paper and create cytoscape df for them
```{r}
#Fuse JUN and FOS nodes
frequency_summary_top100["TF"]<-gsub("JUNB|JUND|JUN|FOSB|FOS","JUN-FOS",frequency_summary_top100$TF)
frequency_summary_top100["target"]<-gsub("JUNB|JUND|JUN|FOSB|FOS","JUN-FOS",frequency_summary_top100$target)

paper_top100_overlap<-unique(gsub("JUN|FOS","JUN-FOS",paper_top100_overlap))


#Create dataframe with only paper overlaps
frequency_summary_top100_paper_tf<-frequency_summary_top100[frequency_summary_top100$TF %in% paper_top100_overlap,]
frequency_summary_top100_paper_target<-frequency_summary_top100[!frequency_summary_top100$TF %in% paper_top100_overlap,][frequency_summary_top100[!frequency_summary_top100$TF %in% paper_top100_overlap,]$target %in% paper_top100_overlap,]

frequency_summary_top100_paper<-rbind(frequency_summary_top100_paper_tf,frequency_summary_top100_paper_target)

#Remove self regulation
remove<-c()
for (x in seq(nrow(frequency_summary_top100_paper))){
  if(frequency_summary_top100_paper$TF[x]==frequency_summary_top100_paper$target[x]){
    remove<-append(remove,x)
  }
}

frequency_summary_top100_paper<-frequency_summary_top100_paper[-remove,]
frequency_summary_top100_paper<-frequency_summary_top100_paper[order(frequency_summary_top100_paper$TF),]

#Create all interactions
frequency_summary_top100_paper_interactions<-c()
for(x in seq(nrow(frequency_summary_top100_paper))){
    frequency_summary_top100_paper_interactions<-append(frequency_summary_top100_paper_interactions,paste0(frequency_summary_top100_paper$TF[x],"->",frequency_summary_top100_paper$target[x]))
}

#Find duplicates, remove them and assign new NIS
duplicate_interactions<-unique(frequency_summary_top100_paper_interactions[duplicated(frequency_summary_top100_paper_interactions)])

new_nis<-vector("list",length(duplicate_interactions))
names(new_nis)<-duplicate_interactions
for(x in duplicate_interactions){
  pos<-grep(x,frequency_summary_top100_paper_interactions)
  new_nis[[x]]<-mean(frequency_summary_top100_paper[pos,]$NIS)
}

frequency_summary_top100_paper_interactions_nis<-frequency_summary_top100_paper$NIS
names(frequency_summary_top100_paper_interactions_nis)<-frequency_summary_top100_paper_interactions
frequency_summary_top100_paper_interactions_nis<-frequency_summary_top100_paper_interactions_nis[-which(duplicated(frequency_summary_top100_paper_interactions))]
frequency_summary_top100_paper_interactions_nis[duplicate_interactions]<-unlist(new_nis)

frequency_summary_top100_paper<-frequency_summary_top100_paper[-which(duplicated(frequency_summary_top100_paper_interactions)),]
frequency_summary_top100_paper["NIS"]<-frequency_summary_top100_paper_interactions_nis

#Introduce lost cistrome confirmed interactions
frequency_cistrome_summary_top100_paper<-frequency_cistrome_summary_top100
frequency_cistrome_summary_top100_paper["TF"]<-gsub("JUNB|JUND|JUN|FOSB|FOS","JUN-FOS",frequency_cistrome_summary_top100_paper$TF)
frequency_cistrome_summary_top100_paper["target"]<-gsub("JUNB|JUND|JUN|FOSB|FOS","JUN-FOS",frequency_cistrome_summary_top100_paper$target)

cistrome_paper<-c()
for (x in seq(nrow(frequency_cistrome_summary_top100_paper))){
  tfs<-which(frequency_summary_top100_paper$TF==frequency_cistrome_summary_top100_paper$TF[x])
  targets<-which(frequency_summary_top100_paper$target==frequency_cistrome_summary_top100_paper$target[x])
  pos<-tfs[tfs %in% targets]
  if(length(pos)!=0){
    cistrome_paper<-append(cistrome_paper,pos)
  }
}

frequency_summary_top100_paper[cistrome_paper,"cistrome_filter"]<-T

#Modify JUN-FOS vertices to get "most_expressed in" right
vertices.df_paper<-vertices.df
vertices.df_paper[,1]<-gsub("JUNB|JUND|JUN|FOSB|FOS","JUN-FOS",vertices.df_paper[,1])
vertices.df_paper<-vertices.df_paper[-which(duplicated(vertices.df_paper[,1])),]

vertices.df_paper<-vertices.df_paper[vertices.df_paper[,1] %in% unique(c(frequency_summary_top100_paper$TF,frequency_summary_top100_paper$target)), ]

#Compute Louvain clustering and add group number to the vertices.df_paper
g_paper_overlap <- graph_from_data_frame(d = frequency_summary_top100_paper, directed = F, vertices = vertices.df_paper)

louvain_clustering_paper<-cluster_louvain(g_paper_overlap,weight=frequency_summary_top100_paper$NIS, resolution = 0.2)
louvain_clustering_paper_communities<-louvain_clustering_paper$membership
names(louvain_clustering_paper_communities)<-louvain_clustering_paper$names
louvain_clustering_paper_communities<-split(names(louvain_clustering_paper_communities),louvain_clustering_paper_communities)

colnames(vertices.df_paper)[1]<-"nodes"
vertices.df_paper["group"]<-0

for (x in names(louvain_clustering_paper_communities)){
  for (y in louvain_clustering_paper_communities[[x]]){
    pos<-which(vertices.df_paper$nodes==y)
    vertices.df_paper[pos,"group"]<-x
  }
}

#Add TF and target missing information
cytoscape_paper_overlap<-frequency_summary_top100_paper

cytoscape_paper_overlap["TF_most_expressed_in"]<-"none"
cytoscape_paper_overlap["TF_group"]<-0
cytoscape_paper_overlap["target_most_expressed_in"]<-"none"
cytoscape_paper_overlap["target_group"]<-0

for (x in seq(nrow(cytoscape_paper_overlap))){
  pos<-which(vertices.df_paper$nodes==cytoscape_paper_overlap$TF[x])
  cytoscape_paper_overlap[x,"TF_most_expressed_in"]<-cytoscape_nodes[pos,"most_expressed_in"]
  cytoscape_paper_overlap[x,"TF_group"]<-vertices.df_paper[pos,"group"]
  
  pos2<-which(vertices.df_paper$nodes==cytoscape_paper_overlap$target[x])
  cytoscape_paper_overlap[x,"target_most_expressed_in"]<-vertices.df_paper[pos2,"most_expressed_in"]
  cytoscape_paper_overlap[x,"target_group"]<-vertices.df_paper[pos2,"group"]
}

cytoscape_paper_overlap<-cytoscape_paper_overlap[,c(1,5,6,2,7,8,3,4)]

#Save the table
setwd(analysis_directory)
write.table(cytoscape_paper_overlap, file='cytoscape_paper_overlap.tsv', quote=FALSE, sep='\t', row.names = F)
```